让我继续完成自动化运维平台设计的内容：

### 5.2 Kubernetes部署（续）

#### 5.2.2 Helm Chart部署

Helm是Kubernetes的包管理工具，可以简化应用的部署和管理。通过Helm Chart，可以将自动化运维平台的所有组件打包为一个可重用、可配置的部署单元。

```yaml
# Chart.yaml
apiVersion: v2
name: ops-platform
description: 自动化运维平台
type: application
version: 0.1.0
appVersion: "1.0.0"
```

```yaml
# values.yaml
global:
  environment: production
  imageRegistry: ops-registry

frontend:
  replicaCount: 2
  image:
    repository: ops-frontend
    tag: latest
  service:
    type: ClusterIP
    port: 80
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi
  ingress:
    enabled: true
    host: ops.example.com
    tls: true

backend:
  replicaCount: 3
  image:
    repository: ops-backend
    tag: latest
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi
  livenessProbe:
    path: /actuator/health/liveness
    initialDelaySeconds: 60
    periodSeconds: 15
  readinessProbe:
    path: /actuator/health/readiness
    initialDelaySeconds: 30
    periodSeconds: 10

database:
  enabled: true
  type: mysql
  version: "8.0"
  host: ops-mysql
  port: 3306
  database: ops_platform
  username: ops_user
  password: ops_password
  persistence:
    enabled: true
    size: 10Gi

redis:
  enabled: true
  version: "6.2"
  persistence:
    enabled: true
    size: 5Gi

prometheus:
  enabled: true
  persistence:
    enabled: true
    size: 20Gi

grafana:
  enabled: true
  adminUser: admin
  adminPassword: admin_password
  persistence:
    enabled: true
    size: 5Gi
  dashboards:
    enabled: true
```

#### 5.2.3 Kubernetes Operator

Kubernetes Operator是一种扩展Kubernetes API的方式，可以实现自定义资源的自动化管理。对于自动化运维平台，可以开发专用的Operator来管理平台特有的资源和操作。

```yaml
# 自定义资源定义(CRD)示例
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: automationtasks.ops.example.com
spec:
  group: ops.example.com
  names:
    kind: AutomationTask
    listKind: AutomationTaskList
    plural: automationtasks
    singular: automationtask
    shortNames:
      - at
  scope: Namespaced
  versions:
    - name: v1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              required:
                - taskType
                - target
              properties:
                taskType:
                  type: string
                  enum:
                    - script
                    - ansible
                    - api
                    - workflow
                target:
                  type: object
                  properties:
                    serverIds:
                      type: array
                      items:
                        type: string
                    serverGroups:
                      type: array
                      items:
                        type: string
                content:
                  type: string
                parameters:
                  type: object
                  additionalProperties: true
                schedule:
                  type: string
                timeout:
                  type: integer
                  minimum: 1
                  maximum: 86400
            status:
              type: object
              properties:
                phase:
                  type: string
                  enum:
                    - Pending
                    - Running
                    - Succeeded
                    - Failed
                startTime:
                  type: string
                  format: date-time
                completionTime:
                  type: string
                  format: date-time
                conditions:
                  type: array
                  items:
                    type: object
                    required:
                      - type
                      - status
                    properties:
                      type:
                        type: string
                      status:
                        type: string
                      reason:
                        type: string
                      message:
                        type: string
                      lastTransitionTime:
                        type: string
                        format: date-time
      subresources:
        status: {}
      additionalPrinterColumns:
        - name: Task Type
          type: string
          jsonPath: .spec.taskType
        - name: Status
          type: string
          jsonPath: .status.phase
        - name: Age
          type: date
          jsonPath: .metadata.creationTimestamp
```

### 5.3 高可用架构

高可用架构是确保自动化运维平台稳定运行的关键，可以通过多种技术手段实现系统的高可用性。

#### 5.3.1 多副本部署

多副本部署是实现高可用的基本方式，通过部署多个相同的服务实例，避免单点故障。

```
┌─────────────────────────────────────────────────────────────┐
│                      负载均衡器 (Load Balancer)              │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐
│  前端实例1  │  前端实例2  │  前端实例3  │     ...     │  前端实例N  │
└─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘
                            │
                            ▼
┌─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐
│  后端实例1  │  后端实例2  │  后端实例3  │     ...     │  后端实例N  │
└─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                  数据库集群 (Database Cluster)               │
└─────────────────────────────────────────────────────────────┘
```

#### 5.3.2 数据库高可用

数据库高可用是确保数据安全和服务可靠性的关键，常见的数据库高可用方案包括：

1. **主从复制**：一个主数据库负责写操作，多个从数据库负责读操作，主库将变更同步到从库。
2. **集群模式**：多个数据库节点组成集群，通过共识算法保证数据一致性。
3. **分片集群**：将数据分散存储在多个数据库节点，提高系统容量和性能。

```
┌─────────────────────────────────────────────────────────────┐
│                        数据库负载均衡器                      │
└───────────────────────────┬─────────────────────────────────┘
                            │
                ┌───────────┴───────────┐
                │                       │
                ▼                       ▼
┌───────────────────────┐   ┌───────────────────────┐
│     主数据库节点      │   │     从数据库节点1     │
│  (Primary Database)   │──►│ (Replica Database 1)  │
└───────────────────────┘   └───────────────────────┘
                                        │
                                        │
                                        ▼
                            ┌───────────────────────┐
                            │     从数据库节点2     │
                            │ (Replica Database 2)  │
                            └───────────────────────┘
                                        │
                                        │
                                        ▼
                            ┌───────────────────────┐
                            │     从数据库节点3     │
                            │ (Replica Database 3)  │
                            └───────────────────────┘
```

#### 5.3.3 缓存高可用

缓存高可用可以提高系统性能和可靠性，常见的缓存高可用方案包括：

1. **Redis Sentinel**：监控Redis主从节点，自动故障转移。
2. **Redis Cluster**：分片集群，数据分布在多个节点，提供高可用性和可扩展性。
3. **多级缓存**：结合本地缓存和分布式缓存，提高缓存命中率和可靠性。

```
┌─────────────────────────────────────────────────────────────┐
│                       Redis Sentinel集群                     │
└───────────┬───────────────────────────────────┬─────────────┘
            │                                   │
            ▼                                   ▼
┌───────────────────────┐           ┌───────────────────────┐
│    Sentinel节点1      │           │    Sentinel节点2      │
└───────────────────────┘           └───────────────────────┘
            │                                   │
            └───────────────┬───────────────────┘
                            │
                            ▼
┌───────────────────────┐   │   ┌───────────────────────┐
│     Redis主节点       │◄──┴──►│    Redis从节点1      │
└───────────────────────┘       └───────────────────────┘
                                            │
                                            ▼
                                ┌───────────────────────┐
                                │    Redis从节点2      │
                                └───────────────────────┘
```

#### 5.3.4 服务发现与注册

服务发现与注册是微服务架构中实现高可用的重要机制，常见的服务发现方案包括：

1. **Kubernetes Service**：Kubernetes内置的服务发现机制。
2. **Consul**：分布式服务发现和配置管理工具。
3. **Eureka**：Netflix开源的服务发现框架。
4. **Nacos**：阿里巴巴开源的动态服务发现、配置管理和服务管理平台。

```
┌─────────────────────────────────────────────────────────────┐
│                       服务注册中心                           │
│                   (Service Registry)                         │
└───────────────────────────┬─────────────────────────────────┘
                            │
            ┌───────────────┼───────────────┐
            │               │               │
            ▼               ▼               ▼
┌───────────────────┐ ┌───────────────┐ ┌───────────────┐
│    服务提供者1    │ │  服务提供者2  │ │  服务提供者3  │
│ (Service Provider)│ │(Service Provider)│(Service Provider)│
└───────────────────┘ └───────────────┘ └───────────────┘
            ▲               ▲               ▲
            │               │               │
            └───────────────┼───────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       服务消费者                             │
│                   (Service Consumer)                         │
└─────────────────────────────────────────────────────────────┘
```

### 5.4 安全架构

安全架构是自动化运维平台的重要组成部分，需要从多个层面保障系统安全。

#### 5.4.1 网络安全

网络安全是保障系统安全的基础，常见的网络安全措施包括：

1. **网络隔离**：将不同安全级别的系统部署在不同的网络区域。
2. **防火墙**：控制网络流量，阻止未授权访问。
3. **VPN**：通过加密通道安全访问内部系统。
4. **WAF**：Web应用防火墙，防止Web攻击。

```
┌─────────────────────────────────────────────────────────────┐
│                       互联网 (Internet)                      │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       防火墙 (Firewall)                      │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                  Web应用防火墙 (WAF)                         │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                  负载均衡器 (Load Balancer)                  │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                  应用服务器 (Application Servers)            │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                  内部防火墙 (Internal Firewall)              │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                  数据库服务器 (Database Servers)             │
└─────────────────────────────────────────────────────────────┘
```

#### 5.4.2 身份认证与授权

身份认证与授权是控制系统访问权限的关键，常见的认证授权方案包括：

1. **OAuth 2.0**：开放授权标准，用于第三方应用授权。
2. **OIDC**：基于OAuth 2.0的身份认证协议。
3. **RBAC**：基于角色的访问控制，根据用户角色分配权限。
4. **ABAC**：基于属性的访问控制，根据用户属性和环境条件控制访问。

```java
// RBAC权限模型示例
@Entity
@Table(name = "users")
public class User {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(nullable = false, unique = true)
    private String username;
    
    @Column(nullable = false)
    private String password;
    
    @Column(nullable = false)
    private String email;
    
    @ManyToMany(fetch = FetchType.EAGER)
    @JoinTable(
        name = "user_roles",
        joinColumns = @JoinColumn(name = "user_id"),
        inverseJoinColumns = @JoinColumn(name = "role_id")
    )
    private Set<Role> roles = new HashSet<>();
    
    // 省略getter和setter方法
}

@Entity
@Table(name = "roles")
public class Role {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(nullable = false, unique = true)
    private String name;
    
    @ManyToMany(fetch = FetchType.EAGER)
    @JoinTable(
        name = "role_permissions",
        joinColumns = @JoinColumn(name = "role_id"),
        inverseJoinColumns = @JoinColumn(name = "permission_id")
    )
    private Set<Permission> permissions = new HashSet<>();
    
    // 省略getter和setter方法
}

@Entity
@Table(name = "permissions")
public class Permission {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(nullable = false, unique = true)
    private String name;
    
    @Column(nullable = false)
    private String resource;
    
    @Column(nullable = false)
    private String action;
    
    // 省略getter和setter方法
}
```

#### 5.4.3 数据安全

数据安全是保护敏感信息的关键，常见的数据安全措施包括：

1. **数据加密**：对敏感数据进行加密存储和传输。
2. **数据脱敏**：对敏感数据进行脱敏处理，减少泄露风险。
3. **数据备份**：定期备份数据，防止数据丢失。
4. **数据审计**：记录数据访问和修改操作，便于追溯。

```java
// 数据加密示例
@Service
public class EncryptionService {
    
    private final String algorithm = "AES/GCM/NoPadding";
    private final int tagLengthBit = 128;
    private final int ivLengthByte = 12;
    private final SecretKey secretKey;
    
    public EncryptionService(@Value("${encryption.key}") String base64Key) {
        byte[] decodedKey = Base64.getDecoder().decode(base64Key);
        this.secretKey = new SecretKeySpec(decodedKey, "AES");
    }
    
    public String encrypt(String plainText) {
        try {
            byte[] iv = new byte[ivLengthByte];
            SecureRandom random = new SecureRandom();
            random.nextBytes(iv);
            
            Cipher cipher = Cipher.getInstance(algorithm);
            GCMParameterSpec parameterSpec = new GCMParameterSpec(tagLengthBit, iv);
            cipher.init(Cipher.ENCRYPT_MODE, secretKey, parameterSpec);
            
            byte[] cipherText = cipher.doFinal(plainText.getBytes(StandardCharsets.UTF_8));
            
            ByteBuffer byteBuffer = ByteBuffer.allocate(iv.length + cipherText.length);
            byteBuffer.put(iv);
            byteBuffer.put(cipherText);
            
            return Base64.getEncoder().encodeToString(byteBuffer.array());
        } catch (Exception e) {
            throw new RuntimeException("加密失败", e);
        }
    }
    
    public String decrypt(String encryptedText) {
        try {
            byte[] decodedText = Base64.getDecoder().decode(encryptedText);
            ByteBuffer byteBuffer = ByteBuffer.wrap(decodedText);
            
            byte[] iv = new byte[ivLengthByte];
            byteBuffer.get(iv);
            
            byte[] cipherText = new byte[byteBuffer.remaining()];
            byteBuffer.get(cipherText);
            
            Cipher cipher = Cipher.getInstance(algorithm);
            GCMParameterSpec parameterSpec = new GCMParameterSpec(tagLengthBit, iv);
            cipher.init(Cipher.DECRYPT_MODE, secretKey, parameterSpec);
            
            byte[] plainText = cipher.doFinal(cipherText);
            return new String(plainText, StandardCharsets.UTF_8);
        } catch (Exception e) {
            throw new RuntimeException("解密失败", e);
        }
    }
}
```

## 6. 自动化运维平台实施与运营

### 6.1 实施方法论

自动化运维平台的实施需要遵循一定的方法论，确保项目顺利进行。

#### 6.1.1 阶段划分

自动化运维平台实施可以划分为以下阶段：

1. **需求分析**：收集和分析用户需求，确定平台功能和范围。
2. **方案设计**：根据需求设计平台架构和功能模块。
3. **开发实现**：按照设计方案开发平台功能。
4. **测试验证**：对平台功能进行测试和验证。
5. **部署上线**：将平台部署到生产环境并上线使用。
6. **运营维护**：对平台进行日常运营和维护。

#### 6.1.2 敏捷开发

敏捷开发是适合自动化运维平台实施的开发方法，具有迭代快、反馈及时的特点。

```
┌─────────────────────────────────────────────────────────────┐
│                       产品待办列表                           │
│                    (Product Backlog)                         │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       迭代计划会议                           │
│                  (Sprint Planning Meeting)                   │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       迭代待办列表                           │
│                      (Sprint Backlog)                        │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       每日站会                               │
│                    (Daily Scrum)                             │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       迭代评审会议                           │
│                   (Sprint Review Meeting)                    │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       迭代回顾会议                           │
│                (Sprint Retrospective Meeting)                │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       产品增量                               │
│                   (Product Increment)                        │
└─────────────────────────────────────────────────────────────┘
```

#### 6.1.3 DevOps实践

DevOps实践是自动化运维平台实施的重要方法，强调开发和运维的协作，实现持续集成和持续交付。

```
┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐
│  计划   │────►│  编码   │────►│  构建   │────►│  测试   │
└─────────┘     └─────────┘     └─────────┘     └─────────┘
    ▲                                                │
    │                                                │
    │                                                ▼
┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐
│  监控   │◄────│  运营   │◄────│  部署   │◄────│  发布   │
└─────────┘     └─────────┘     └─────────┘     └─────────┘
```

### 6.2 运营管理

运营管理是自动化运维平台长期稳定运行的保障，包括日常运维、性能优化、安全管理等方面。

#### 6.2.1 日常运维

日常运维是保障平台正常运行的基础工作，包括以下内容：

1. **系统监控**：监控平台各组件的运行状态和性能指标。
2. **日志管理**：收集和分析平台日志，及时发现和处理异常。
3. **备份恢复**：定期备份平台数据，确保数据安全。
4. **补丁管理**：及时更新系统补丁，修复安全漏洞。

```yaml
# Prometheus监控配置示例
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager:9093

rule_files:
  - "rules/node_rules.yml"
  - "rules/app_rules.yml"
  - "rules/db_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    static_configs:
      - targets:
        - 'node-exporter-1:9100'
        - 'node-exporter-2:9100'
        - 'node-exporter-3:9100'

  - job_name: 'ops_platform'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets:
        - 'ops-backend-1:8080'
        - 'ops-backend-2:8080'
        - 'ops-backend-3:8080'

  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
```

#### 6.2.2 性能优化

性能优化是提升平台用户体验和资源利用率的重要工作，包括以下方面：

1. **前端优化**：减少页面加载时间，优化用户交互体验。
2. **后端优化**：提高接口响应速度，优化数据库查询。
3. **数据库优化**：优化数据库结构和查询语句，提高数据访问效率。
4. **缓存优化**：合理使用缓存，减少重复计算和数据库访问。

```java
// 缓存优化示例
@Service
public class ServerMetricsService {
    
    private final ServerMetricsRepository metricsRepository;
    private final CacheManager cacheManager;
    
    @Autowired
    public ServerMetricsService(
            ServerMetricsRepository metricsRepository,
            CacheManager cacheManager) {
        this.metricsRepository = metricsRepository;
        this.cacheManager = cacheManager;
    }
    
    @Cacheable(value = "serverMetrics", key = "#serverId + '_' + #startTime.toEpochMilli() + '_' + #endTime.toEpochMilli()")
    public List<ServerMetrics> getServerMetrics(Long serverId, Instant startTime, Instant endTime) {
        return metricsRepository.findByServerIdAndTimeBetween(serverId, startTime, endTime);
    }
    
    @Cacheable(value = "serverMetricsSummary", key = "#serverId")
    public ServerMetricsSummary getServerMetricsSummary(Long serverId) {
        // 计算服务器指标摘要，包括平均值、最大值、最小值等
        List<ServerMetrics> recentMetrics = metricsRepository.findTop100ByServerIdOrderByTimeDesc(serverId);
        
        double avgCpuUsage = recentMetrics.stream()
                .mapToDouble(ServerMetrics::getCpuUsage)
                .average()
                .orElse(0);
        
        double maxCpuUsage = recentMetrics.stream()
                .mapToDouble(ServerMetrics::getCpuUsage)
                .max()
                .orElse(0);
        
        double avgMemoryUsage = recentMetrics.stream()
                .mapToDouble(ServerMetrics::getMemoryUsage)
                .average()
                .orElse(0);
        
        double maxMemoryUsage = recentMetrics.stream()
                .mapToDouble(ServerMetrics::getMemoryUsage)
                .max()
                .orElse(0);
        
        return new ServerMetricsSummary(serverId, avgCpuUsage, maxCpuUsage, avgMemoryUsage, maxMemoryUsage);
    }
    
    @CacheEvict(value = "serverMetricsSummary", key = "#serverId")
    public void refreshServerMetricsSummary(Long serverId) {
        // 清除缓存，下次访问时重新计算
    }
    
    @Scheduled(fixedRate = 3600000) // 每小时执行一次
    public void evictAllCaches() {
        cacheManager.getCacheNames().forEach(cacheName -> {
            Cache cache = cacheManager.getCache(cacheName);
            if (cache != null) {
                cache.clear();
            }
        });
    }
}
```

#### 6.2.3 安全管理

安全管理是保障平台和数据安全的重要工作，包括以下方面：

1. **漏洞管理**：定期进行安全扫描，及时修复安全漏洞。
2. **访问控制**：严格控制平台访问权限，实施最小权限原则。
3. **安全审计**：记录和分析安全事件，及时发现安全威胁。
4. **安全培训**：对运维人员进行安全意识和技能培训。

```java
让我继续完成自动化运维平台设计的内容：

### 6.2 运营管理（续）

#### 6.2.3 安全管理（续）

```java
// 安全审计日志服务示例
@Service
public class SecurityAuditService {
    
    private final SecurityAuditRepository auditRepository;
    private final UserService userService;
    
    @Autowired
    public SecurityAuditService(
            SecurityAuditRepository auditRepository,
            UserService userService) {
        this.auditRepository = auditRepository;
        this.userService = userService;
    }
    
    public void logLogin(String username, String ipAddress, boolean success, String failReason) {
        SecurityAuditLog log = new SecurityAuditLog();
        log.setEventType(SecurityEventType.LOGIN);
        log.setUsername(username);
        log.setIpAddress(ipAddress);
        log.setSuccess(success);
        log.setDetails(success ? "登录成功" : "登录失败: " + failReason);
        log.setTimestamp(Instant.now());
        
        auditRepository.save(log);
    }
    
    public void logLogout(String username, String ipAddress) {
        SecurityAuditLog log = new SecurityAuditLog();
        log.setEventType(SecurityEventType.LOGOUT);
        log.setUsername(username);
        log.setIpAddress(ipAddress);
        log.setSuccess(true);
        log.setDetails("用户登出");
        log.setTimestamp(Instant.now());
        
        auditRepository.save(log);
    }
    
    public void logPermissionChange(String adminUsername, String targetUsername, 
                                   String permission, String action, String ipAddress) {
        SecurityAuditLog log = new SecurityAuditLog();
        log.setEventType(SecurityEventType.PERMISSION_CHANGE);
        log.setUsername(adminUsername);
        log.setTargetUsername(targetUsername);
        log.setIpAddress(ipAddress);
        log.setSuccess(true);
        log.setDetails(String.format("权限变更: %s %s 权限 %s", action, targetUsername, permission));
        log.setTimestamp(Instant.now());
        
        auditRepository.save(log);
    }
    
    public void logSensitiveOperation(String username, String operation, 
                                     String targetResource, String ipAddress) {
        SecurityAuditLog log = new SecurityAuditLog();
        log.setEventType(SecurityEventType.SENSITIVE_OPERATION);
        log.setUsername(username);
        log.setIpAddress(ipAddress);
        log.setSuccess(true);
        log.setDetails(String.format("敏感操作: %s 对资源 %s", operation, targetResource));
        log.setTimestamp(Instant.now());
        
        auditRepository.save(log);
    }
    
    public void logSecurityAlert(String alertType, String description, 
                               String sourceIp, String targetUsername) {
        SecurityAuditLog log = new SecurityAuditLog();
        log.setEventType(SecurityEventType.SECURITY_ALERT);
        log.setTargetUsername(targetUsername);
        log.setIpAddress(sourceIp);
        log.setSuccess(false);
        log.setDetails(String.format("安全告警: %s - %s", alertType, description));
        log.setTimestamp(Instant.now());
        
        auditRepository.save(log);
    }
    
    public Page<SecurityAuditLog> searchAuditLogs(SecurityAuditSearchCriteria criteria, Pageable pageable) {
        return auditRepository.findByCriteria(criteria, pageable);
    }
    
    @Scheduled(cron = "0 0 0 * * ?") // 每天凌晨执行
    public void analyzeSecurityEvents() {
        Instant yesterday = Instant.now().minus(1, ChronoUnit.DAYS);
        List<SecurityAuditLog> failedLogins = auditRepository.findByEventTypeAndSuccessAndTimestampAfter(
                SecurityEventType.LOGIN, false, yesterday);
        
        // 分析登录失败模式
        Map<String, Long> failedLoginsByUsername = failedLogins.stream()
                .collect(Collectors.groupingBy(SecurityAuditLog::getUsername, Collectors.counting()));
        
        Map<String, Long> failedLoginsByIp = failedLogins.stream()
                .collect(Collectors.groupingBy(SecurityAuditLog::getIpAddress, Collectors.counting()));
        
        // 检测暴力破解尝试
        failedLoginsByUsername.forEach((username, count) -> {
            if (count >= 5) {
                logSecurityAlert("暴力破解尝试", 
                               String.format("检测到对用户 %s 的多次登录失败 (%d 次)", username, count),
                               "", username);
            }
        });
        
        failedLoginsByIp.forEach((ip, count) -> {
            if (count >= 10) {
                logSecurityAlert("可疑IP活动", 
                               String.format("检测到来自IP %s 的多次登录失败 (%d 次)", ip, count),
                               ip, "");
            }
        });
    }
}
```

#### 6.2.4 变更管理

变更管理是控制系统变更风险的重要工作，包括以下方面：

1. **变更评估**：评估变更的影响和风险，制定变更计划。
2. **变更审批**：对变更进行多级审批，确保变更合理合规。
3. **变更实施**：按照计划实施变更，并进行变更验证。
4. **变更回滚**：当变更出现问题时，能够快速回滚到变更前的状态。

```java
// 变更管理服务示例
@Service
public class ChangeManagementService {
    
    private final ChangeRequestRepository changeRequestRepository;
    private final ChangeApprovalRepository approvalRepository;
    private final UserService userService;
    private final NotificationService notificationService;
    
    @Autowired
    public ChangeManagementService(
            ChangeRequestRepository changeRequestRepository,
            ChangeApprovalRepository approvalRepository,
            UserService userService,
            NotificationService notificationService) {
        this.changeRequestRepository = changeRequestRepository;
        this.approvalRepository = approvalRepository;
        this.userService = userService;
        this.notificationService = notificationService;
    }
    
    @Transactional
    public ChangeRequest createChangeRequest(ChangeRequestDTO requestDTO, String creatorUsername) {
        User creator = userService.findByUsername(creatorUsername)
                .orElseThrow(() -> new UsernameNotFoundException("用户不存在: " + creatorUsername));
        
        ChangeRequest request = new ChangeRequest();
        request.setTitle(requestDTO.getTitle());
        request.setDescription(requestDTO.getDescription());
        request.setChangeType(requestDTO.getChangeType());
        request.setRiskLevel(calculateRiskLevel(requestDTO));
        request.setAffectedSystems(requestDTO.getAffectedSystems());
        request.setImplementationPlan(requestDTO.getImplementationPlan());
        request.setRollbackPlan(requestDTO.getRollbackPlan());
        request.setPlannedStartTime(requestDTO.getPlannedStartTime());
        request.setPlannedEndTime(requestDTO.getPlannedEndTime());
        request.setCreator(creator);
        request.setStatus(ChangeStatus.DRAFT);
        request.setCreatedAt(Instant.now());
        
        ChangeRequest savedRequest = changeRequestRepository.save(request);
        
        // 根据风险级别确定审批流程
        List<User> approvers = determineApprovers(savedRequest);
        for (int i = 0; i < approvers.size(); i++) {
            ChangeApproval approval = new ChangeApproval();
            approval.setChangeRequest(savedRequest);
            approval.setApprover(approvers.get(i));
            approval.setApprovalOrder(i + 1);
            approval.setStatus(i == 0 ? ApprovalStatus.PENDING : ApprovalStatus.WAITING);
            approvalRepository.save(approval);
        }
        
        return savedRequest;
    }
    
    @Transactional
    public ChangeRequest submitChangeRequest(Long requestId, String username) {
        ChangeRequest request = changeRequestRepository.findById(requestId)
                .orElseThrow(() -> new ResourceNotFoundException("变更请求不存在: " + requestId));
        
        if (!request.getCreator().getUsername().equals(username)) {
            throw new AccessDeniedException("只有创建者可以提交变更请求");
        }
        
        if (request.getStatus() != ChangeStatus.DRAFT) {
            throw new IllegalStateException("只有草稿状态的变更请求可以提交");
        }
        
        request.setStatus(ChangeStatus.PENDING_APPROVAL);
        request.setSubmittedAt(Instant.now());
        
        ChangeRequest savedRequest = changeRequestRepository.save(request);
        
        // 通知第一个审批人
        List<ChangeApproval> approvals = approvalRepository.findByChangeRequestIdOrderByApprovalOrder(requestId);
        if (!approvals.isEmpty()) {
            ChangeApproval firstApproval = approvals.get(0);
            notificationService.sendNotification(
                    firstApproval.getApprover().getUsername(),
                    "变更请求等待审批",
                    String.format("变更请求 '%s' 需要您的审批", request.getTitle()),
                    NotificationType.CHANGE_APPROVAL,
                    Map.of("changeRequestId", requestId.toString())
            );
        }
        
        return savedRequest;
    }
    
    @Transactional
    public ChangeApproval approveChangeRequest(Long requestId, String approverUsername, String comments) {
        ChangeRequest request = changeRequestRepository.findById(requestId)
                .orElseThrow(() -> new ResourceNotFoundException("变更请求不存在: " + requestId));
        
        if (request.getStatus() != ChangeStatus.PENDING_APPROVAL) {
            throw new IllegalStateException("变更请求不在审批状态");
        }
        
        User approver = userService.findByUsername(approverUsername)
                .orElseThrow(() -> new UsernameNotFoundException("用户不存在: " + approverUsername));
        
        ChangeApproval approval = approvalRepository.findByChangeRequestIdAndApproverIdAndStatus(
                requestId, approver.getId(), ApprovalStatus.PENDING)
                .orElseThrow(() -> new AccessDeniedException("您不是当前审批人"));
        
        approval.setStatus(ApprovalStatus.APPROVED);
        approval.setComments(comments);
        approval.setApprovedAt(Instant.now());
        
        ChangeApproval savedApproval = approvalRepository.save(approval);
        
        // 查找下一个审批人
        List<ChangeApproval> approvals = approvalRepository.findByChangeRequestIdOrderByApprovalOrder(requestId);
        boolean allApproved = true;
        boolean nextApproverNotified = false;
        
        for (ChangeApproval nextApproval : approvals) {
            if (nextApproval.getStatus() == ApprovalStatus.WAITING) {
                nextApproval.setStatus(ApprovalStatus.PENDING);
                approvalRepository.save(nextApproval);
                
                notificationService.sendNotification(
                        nextApproval.getApprover().getUsername(),
                        "变更请求等待审批",
                        String.format("变更请求 '%s' 需要您的审批", request.getTitle()),
                        NotificationType.CHANGE_APPROVAL,
                        Map.of("changeRequestId", requestId.toString())
                );
                
                nextApproverNotified = true;
                allApproved = false;
                break;
            } else if (nextApproval.getStatus() == ApprovalStatus.PENDING) {
                allApproved = false;
            }
        }
        
        // 如果所有审批人都已审批，更新变更请求状态
        if (allApproved) {
            request.setStatus(ChangeStatus.APPROVED);
            request.setApprovedAt(Instant.now());
            changeRequestRepository.save(request);
            
            notificationService.sendNotification(
                    request.getCreator().getUsername(),
                    "变更请求已批准",
                    String.format("您的变更请求 '%s' 已获得所有审批", request.getTitle()),
                    NotificationType.CHANGE_APPROVED,
                    Map.of("changeRequestId", requestId.toString())
            );
        }
        
        return savedApproval;
    }
    
    @Transactional
    public ChangeApproval rejectChangeRequest(Long requestId, String approverUsername, String comments) {
        ChangeRequest request = changeRequestRepository.findById(requestId)
                .orElseThrow(() -> new ResourceNotFoundException("变更请求不存在: " + requestId));
        
        if (request.getStatus() != ChangeStatus.PENDING_APPROVAL) {
            throw new IllegalStateException("变更请求不在审批状态");
        }
        
        User approver = userService.findByUsername(approverUsername)
                .orElseThrow(() -> new UsernameNotFoundException("用户不存在: " + approverUsername));
        
        ChangeApproval approval = approvalRepository.findByChangeRequestIdAndApproverIdAndStatus(
                requestId, approver.getId(), ApprovalStatus.PENDING)
                .orElseThrow(() -> new AccessDeniedException("您不是当前审批人"));
        
        approval.setStatus(ApprovalStatus.REJECTED);
        approval.setComments(comments);
        approval.setApprovedAt(Instant.now());
        
        ChangeApproval savedApproval = approvalRepository.save(approval);
        
        // 更新变更请求状态
        request.setStatus(ChangeStatus.REJECTED);
        changeRequestRepository.save(request);
        
        notificationService.sendNotification(
                request.getCreator().getUsername(),
                "变更请求被拒绝",
                String.format("您的变更请求 '%s' 被拒绝", request.getTitle()),
                NotificationType.CHANGE_REJECTED,
                Map.of(
                        "changeRequestId", requestId.toString(),
                        "rejectedBy", approverUsername,
                        "comments", comments
                )
        );
        
        return savedApproval;
    }
    
    @Transactional
    public ChangeRequest startImplementation(Long requestId, String username) {
        ChangeRequest request = changeRequestRepository.findById(requestId)
                .orElseThrow(() -> new ResourceNotFoundException("变更请求不存在: " + requestId));
        
        if (request.getStatus() != ChangeStatus.APPROVED) {
            throw new IllegalStateException("只有已批准的变更请求可以开始实施");
        }
        
        if (!request.getCreator().getUsername().equals(username)) {
            throw new AccessDeniedException("只有创建者可以开始实施变更");
        }
        
        request.setStatus(ChangeStatus.IMPLEMENTING);
        request.setImplementationStartedAt(Instant.now());
        
        return changeRequestRepository.save(request);
    }
    
    @Transactional
    public ChangeRequest completeImplementation(Long requestId, String username, ImplementationResultDTO resultDTO) {
        ChangeRequest request = changeRequestRepository.findById(requestId)
                .orElseThrow(() -> new ResourceNotFoundException("变更请求不存在: " + requestId));
        
        if (request.getStatus() != ChangeStatus.IMPLEMENTING) {
            throw new IllegalStateException("只有正在实施的变更请求可以完成实施");
        }
        
        if (!request.getCreator().getUsername().equals(username)) {
            throw new AccessDeniedException("只有创建者可以完成实施变更");
        }
        
        request.setStatus(resultDTO.isSuccess() ? ChangeStatus.COMPLETED : ChangeStatus.FAILED);
        request.setImplementationCompletedAt(Instant.now());
        request.setImplementationResult(resultDTO.getResult());
        request.setImplementationNotes(resultDTO.getNotes());
        
        return changeRequestRepository.save(request);
    }
    
    private RiskLevel calculateRiskLevel(ChangeRequestDTO requestDTO) {
        // 根据变更类型、影响系统、计划时间等因素计算风险级别
        int riskScore = 0;
        
        // 根据变更类型评估风险
        switch (requestDTO.getChangeType()) {
            case EMERGENCY:
                riskScore += 5;
                break;
            case STANDARD:
                riskScore += 3;
                break;
            case NORMAL:
                riskScore += 1;
                break;
        }
        
        // 根据影响系统数量评估风险
        int affectedSystemCount = requestDTO.getAffectedSystems().size();
        if (affectedSystemCount > 5) {
            riskScore += 5;
        } else if (affectedSystemCount > 2) {
            riskScore += 3;
        } else {
            riskScore += 1;
        }
        
        // 根据是否有回滚计划评估风险
        if (StringUtils.isEmpty(requestDTO.getRollbackPlan())) {
            riskScore += 5;
        }
        
        // 根据计划时间评估风险（工作时间vs非工作时间）
        LocalTime startTime = requestDTO.getPlannedStartTime().atZone(ZoneId.systemDefault()).toLocalTime();
        if (startTime.isAfter(LocalTime.of(18, 0)) || startTime.isBefore(LocalTime.of(9, 0))) {
            riskScore += 3;
        }
        
        // 根据风险分数确定风险级别
        if (riskScore >= 10) {
            return RiskLevel.HIGH;
        } else if (riskScore >= 6) {
            return RiskLevel.MEDIUM;
        } else {
            return RiskLevel.LOW;
        }
    }
    
    private List<User> determineApprovers(ChangeRequest request) {
        List<User> approvers = new ArrayList<>();
        
        // 根据风险级别确定审批流程
        switch (request.getRiskLevel()) {
            case HIGH:
                // 高风险变更需要团队负责人、部门经理和变更委员会审批
                approvers.addAll(userService.findByRole("TEAM_LEADER"));
                approvers.addAll(userService.findByRole("DEPARTMENT_MANAGER"));
                approvers.addAll(userService.findByRole("CHANGE_COMMITTEE"));
                break;
            case MEDIUM:
                // 中风险变更需要团队负责人和部门经理审批
                approvers.addAll(userService.findByRole("TEAM_LEADER"));
                approvers.addAll(userService.findByRole("DEPARTMENT_MANAGER"));
                break;
            case LOW:
                // 低风险变更只需要团队负责人审批
                approvers.addAll(userService.findByRole("TEAM_LEADER"));
                break;
        }
        
        return approvers;
    }
}
```

### 6.3 持续改进

持续改进是自动化运维平台长期发展的关键，通过不断优化和完善，提升平台的功能和性能。

#### 6.3.1 用户反馈

用户反馈是持续改进的重要来源，通过收集和分析用户反馈，了解用户需求和痛点，指导平台优化方向。

```java
// 用户反馈服务示例
@Service
public class FeedbackService {
    
    private final FeedbackRepository feedbackRepository;
    private final UserService userService;
    private final NotificationService notificationService;
    
    @Autowired
    public FeedbackService(
            FeedbackRepository feedbackRepository,
            UserService userService,
            NotificationService notificationService) {
        this.feedbackRepository = feedbackRepository;
        this.userService = userService;
        this.notificationService = notificationService;
    }
    
    @Transactional
    public Feedback submitFeedback(FeedbackDTO feedbackDTO, String username) {
        User user = userService.findByUsername(username)
                .orElseThrow(() -> new UsernameNotFoundException("用户不存在: " + username));
        
        Feedback feedback = new Feedback();
        feedback.setUser(user);
        feedback.setType(feedbackDTO.getType());
        feedback.setTitle(feedbackDTO.getTitle());
        feedback.setDescription(feedbackDTO.getDescription());
        feedback.setPriority(feedbackDTO.getPriority());
        feedback.setStatus(FeedbackStatus.OPEN);
        feedback.setCreatedAt(Instant.now());
        
        Feedback savedFeedback = feedbackRepository.save(feedback);
        
        // 通知管理员有新的反馈
        List<User> admins = userService.findByRole("ADMIN");
        for (User admin : admins) {
            notificationService.sendNotification(
                    admin.getUsername(),
                    "新的用户反馈",
                    String.format("用户 %s 提交了新的反馈: %s", username, feedbackDTO.getTitle()),
                    NotificationType.NEW_FEEDBACK,
                    Map.of("feedbackId", savedFeedback.getId().toString())
            );
        }
        
        return savedFeedback;
    }
    
    @Transactional
    public Feedback updateFeedbackStatus(Long feedbackId, FeedbackStatus status, String comment, String adminUsername) {
        Feedback feedback = feedbackRepository.findById(feedbackId)
                .orElseThrow(() -> new ResourceNotFoundException("反馈不存在: " + feedbackId));
        
        User admin = userService.findByUsername(adminUsername)
                .orElseThrow(() -> new UsernameNotFoundException("用户不存在: " + adminUsername));
        
        if (!userService.hasRole(admin, "ADMIN")) {
            throw new AccessDeniedException("只有管理员可以更新反馈状态");
        }
        
        feedback.setStatus(status);
        feedback.setAdminComment(comment);
        feedback.setUpdatedAt(Instant.now());
        feedback.setUpdatedBy(admin);
        
        Feedback savedFeedback = feedbackRepository.save(feedback);
        
        // 通知用户反馈状态更新
        notificationService.sendNotification(
                feedback.getUser().getUsername(),
                "反馈状态更新",
                String.format("您的反馈 '%s' 状态已更新为: %s", feedback.getTitle(), status),
                NotificationType.FEEDBACK_UPDATED,
                Map.of(
                        "feedbackId", feedbackId.toString(),
                        "status", status.toString(),
                        "comment", comment
                )
        );
        
        return savedFeedback;
    }
    
    public Page<Feedback> getUserFeedback(String username, Pageable pageable) {
        User user = userService.findByUsername(username)
                .orElseThrow(() -> new UsernameNotFoundException("用户不存在: " + username));
        
        return feedbackRepository.findByUserId(user.getId(), pageable);
    }
    
    public Page<Feedback> getAllFeedback(FeedbackSearchCriteria criteria, Pageable pageable) {
        return feedbackRepository.findByCriteria(criteria, pageable);
    }
    
    public FeedbackStatistics getFeedbackStatistics() {
        long totalFeedback = feedbackRepository.count();
        long openFeedback = feedbackRepository.countByStatus(FeedbackStatus.OPEN);
        long inProgressFeedback = feedbackRepository.countByStatus(FeedbackStatus.IN_PROGRESS);
        long resolvedFeedback = feedbackRepository.countByStatus(FeedbackStatus.RESOLVED);
        long closedFeedback = feedbackRepository.countByStatus(FeedbackStatus.CLOSED);
        
        Map<FeedbackType, Long> feedbackByType = feedbackRepository.countByType();
        Map<FeedbackPriority, Long> feedbackByPriority = feedbackRepository.countByPriority();
        
        return new FeedbackStatistics(
                totalFeedback,
                openFeedback,
                inProgressFeedback,
                resolvedFeedback,
                closedFeedback,
                feedbackByType,
                feedbackByPriority
        );
    }
}
```

#### 6.3.2 性能监控

性能监控是持续改进的重要手段，通过监控平台性能指标，发现性能瓶颈和异常情况，指导性能优化工作。

```java
// 性能监控服务示例
@Service
public class PerformanceMonitorService {
    
    private final PerformanceMetricsRepository metricsRepository;
    private final AlertService alertService;
    
    @Autowired
    public PerformanceMonitorService(
            PerformanceMetricsRepository metricsRepository,
            AlertService alertService) {
        this.metricsRepository = metricsRepository;
        this.alertService = alertService;
    }
    
    @Scheduled(fixedRate = 60000) // 每分钟执行一次
    public void collectPerformanceMetrics() {
        PerformanceMetrics metrics = new PerformanceMetrics();
        metrics.setTimestamp(Instant.now());
        
        // 收集JVM指标
        Runtime runtime = Runtime.getRuntime();
        long totalMemory = runtime.totalMemory();
        long freeMemory = runtime.freeMemory();
        long usedMemory = totalMemory - freeMemory;
        
        metrics.setJvmTotalMemory(totalMemory);
        metrics.setJvmFreeMemory(freeMemory);
        metrics.setJvmUsedMemory(usedMemory);
        metrics.setJvmMemoryUsage((double) usedMemory / totalMemory * 100);
        
        // 收集系统指标
        OperatingSystemMXBean osMBean = ManagementFactory.getOperatingSystemMXBean();
        metrics.setSystemLoadAverage(osMBean.getSystemLoadAverage());
        metrics.setAvailableProcessors(osMBean.getAvailableProcessors());
        
        if (osMBean instanceof com.sun.management.OperatingSystemMXBean) {
            com.sun.management.OperatingSystemMXBean sunOsMBean = (com.sun.management.OperatingSystemMXBean) osMBean;
            metrics.setSystemCpuUsage(sunOsMBean.getCpuLoad() * 100);
            metrics.setProcessCpuUsage(sunOsMBean.getProcessCpuLoad() * 100);
        }
        
        // 收集线程指标
        ThreadMXBean threadMBean = ManagementFactory.getThreadMXBean();
        metrics.setThreadCount(threadMBean.getThreadCount());
        metrics.setPeakThreadCount(threadMBean.getPeakThreadCount());
        metrics.setDaemonThreadCount(threadMBean.getDaemonThreadCount());
        
        // 收集GC指标
        List<GarbageCollectorMXBean> gcMBeans = ManagementFactory.getGarbageCollectorMXBeans();
        long totalGcCount = 0;
        long totalGcTime = 0;
        
        for (GarbageCollectorMXBean gcMBean : gcMBeans) {
            long gcCount = gcMBean.getCollectionCount();
            long gcTime = gcMBean.getCollectionTime();
            
            totalGcCount += gcCount;
            totalGcTime += gcTime;
        }
        
        metrics.setGcCount(totalGcCount);
        metrics.setGcTime(totalGcTime);
        
        // 保存指标
        metricsRepository.save(metrics);
        
        // 检查告警条件
        checkAlertConditions(metrics);
    }
    
    private void checkAlertConditions(PerformanceMetrics metrics) {
        // 检查JVM内存使用率
        if (metrics.getJvmMemoryUsage() > 90) {
            alertService.createAlert(
                    AlertLevel.WARNING,
                    "JVM内存使用率过高",
                    String.format("JVM内存使用率为 %.2f%%", metrics.getJvmMemoryUsage()),
                    "system"
            );
        }
        
        // 检查CPU使用率
        if (metrics.getSystemCpuUsage() > 80) {
            alertService.createAlert(
                    AlertLevel.WARNING,
                    "系统CPU使用率过高",
                    String.format("系统CPU使用率为 %.2f%%", metrics.getSystemCpuUsage()),
                    "system"
            );
        }
        
        // 检查GC频率
        if (metrics.getGcCount() > 100) {
            alertService.createAlert(
                    AlertLevel.WARNING,
                    "GC频率过高",
                    String.format("GC次数为 %d", metrics.getGcCount()),
                    "system"
            );
        }
    }
    
    public List<PerformanceMetrics> getRecentMetrics(int limit) {
        return metricsRepository.findTopNByOrderByTimestampDesc(limit);
    }
    
    public List<PerformanceMetrics> getMetricsByTimeRange(Instant startTime, Instant endTime) {
        return metricsRepository.findByTimestampBetweenOrderByTimestamp(startTime, endTime);
    }
    
    public PerformanceStatistics getPerformanceStatistics(Instant startTime, Instant endTime) {
        List<PerformanceMetrics> metrics = metricsRepository.findByTimestampBetweenOrderByTimestamp(startTime, endTime);
        
        if (metrics.isEmpty()) {
            return new PerformanceStatistics();
        }
        
        DoubleSummaryStatistics jvmMemoryUsageStats = metrics.stream()
                .mapToDouble(PerformanceMetrics::getJvmMemoryUsage)
                .summaryStatistics();
        
        DoubleSummaryStatistics systemCpuUsageStats = metrics.stream()
                .mapToDouble(PerformanceMetrics::getSystemCpuUsage)
                .summaryStatistics();
        
        DoubleSummaryStatistics processCpuUsageStats = metrics.stream()
                .mapToDouble(PerformanceMetrics::getProcessCpuUsage)
                .summaryStat
让我继续完成自动化运维平台设计的内容：

### 6.3 持续改进（续）

#### 6.3.2 性能监控（续）

```java
        DoubleSummaryStatistics processCpuUsageStats = metrics.stream()
                .mapToDouble(PerformanceMetrics::getProcessCpuUsage)
                .summaryStatistics();
        
        LongSummaryStatistics threadCountStats = metrics.stream()
                .mapToLong(PerformanceMetrics::getThreadCount)
                .summaryStatistics();
        
        LongSummaryStatistics gcCountStats = metrics.stream()
                .mapToLong(PerformanceMetrics::getGcCount)
                .summaryStatistics();
        
        LongSummaryStatistics gcTimeStats = metrics.stream()
                .mapToLong(PerformanceMetrics::getGcTime)
                .summaryStatistics();
        
        return new PerformanceStatistics(
                jvmMemoryUsageStats,
                systemCpuUsageStats,
                processCpuUsageStats,
                threadCountStats,
                gcCountStats,
                gcTimeStats
        );
    }
    
    public List<PerformanceMetricsDTO> getPerformanceMetricsForChart(Instant startTime, Instant endTime) {
        List<PerformanceMetrics> metrics = metricsRepository.findByTimestampBetweenOrderByTimestamp(startTime, endTime);
        
        return metrics.stream()
                .map(m -> new PerformanceMetricsDTO(
                        m.getTimestamp(),
                        m.getJvmMemoryUsage(),
                        m.getSystemCpuUsage(),
                        m.getProcessCpuUsage(),
                        m.getThreadCount(),
                        m.getGcCount(),
                        m.getGcTime()
                ))
                .collect(Collectors.toList());
    }
}
```

#### 6.3.3 版本迭代

版本迭代是持续改进的具体实践，通过定期发布新版本，不断增强平台功能和性能，满足用户不断变化的需求。

```
┌─────────────────────────────────────────────────────────────┐
│                       需求收集与分析                         │
│                 (Requirements Collection)                    │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       版本规划                               │
│                   (Version Planning)                         │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       开发与测试                             │
│               (Development and Testing)                      │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       版本发布                               │
│                   (Version Release)                          │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       用户反馈收集                           │
│                 (User Feedback Collection)                   │
└───────────────────────────┬─────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│                       持续优化                               │
│                (Continuous Optimization)                     │
└─────────────────────────────────────────────────────────────┘
```

版本迭代计划示例：

| 版本号 | 发布时间 | 主要功能 | 优化内容 |
|--------|----------|----------|----------|
| v1.0.0 | 2023-06-01 | 基础功能：资产管理、配置管理、任务调度 | 首次发布 |
| v1.1.0 | 2023-07-15 | 监控告警：服务器监控、应用监控、告警管理 | 优化资产管理界面，提高响应速度 |
| v1.2.0 | 2023-09-01 | 自动化运维：自动化脚本、工作流管理 | 优化配置管理功能，增加配置对比和回滚 |
| v1.3.0 | 2023-10-15 | 安全管理：安全扫描、漏洞管理、合规检查 | 优化监控告警功能，增加自定义告警规则 |
| v2.0.0 | 2023-12-01 | 智能运维：AIOps、异常检测、根因分析 | 全面优化用户界面，提升用户体验 |
| v2.1.0 | 2024-02-15 | 多云管理：云资源管理、云成本优化 | 优化自动化运维功能，增加更多预置工作流 |
| v2.2.0 | 2024-04-01 | 容器管理：Kubernetes集成、容器监控 | 优化安全管理功能，增加更多安全检查项 |
| v2.3.0 | 2024-06-15 | DevOps集成：CI/CD集成、代码质量管理 | 优化智能运维功能，提高异常检测准确率 |

#### 6.3.4 技术栈更新

技术栈更新是持续改进的重要方面，通过引入新技术和框架，提升平台的技术能力和竞争力。

技术栈更新计划示例：

| 时间 | 更新内容 | 预期收益 |
|------|----------|----------|
| 2023-Q3 | 前端框架从Vue 2升级到Vue 3 | 提升前端性能和开发效率，支持Composition API |
| 2023-Q4 | 后端框架从Spring Boot 2.x升级到Spring Boot 3.x | 提升后端性能和安全性，支持Java 17新特性 |
| 2024-Q1 | 引入GraphQL替代部分REST API | 优化API查询效率，减少网络传输数据量 |
| 2024-Q2 | 引入WebAssembly技术 | 提升前端复杂计算性能，支持更多客户端功能 |
| 2024-Q3 | 引入服务网格(Service Mesh)技术 | 优化微服务通信，提升系统弹性和可观测性 |
| 2024-Q4 | 引入边缘计算技术 | 支持边缘节点部署，减少网络延迟，提升用户体验 |

## 7. 自动化运维平台未来展望

### 7.1 智能化运维

智能化运维是自动化运维平台的未来发展方向，通过引入人工智能和机器学习技术，实现更高级别的自动化和智能化。

#### 7.1.1 AIOps

AIOps(人工智能运维)是将人工智能技术应用于IT运维的实践，通过机器学习、大数据分析等技术，实现IT运维的智能化和自动化。

```java
// AIOps异常检测服务示例
@Service
public class AnomalyDetectionService {
    
    private final MetricsRepository metricsRepository;
    private final AlertService alertService;
    private final ModelService modelService;
    
    @Autowired
    public AnomalyDetectionService(
            MetricsRepository metricsRepository,
            AlertService alertService,
            ModelService modelService) {
        this.metricsRepository = metricsRepository;
        this.alertService = alertService;
        this.modelService = modelService;
    }
    
    @Scheduled(fixedRate = 300000) // 每5分钟执行一次
    public void detectAnomalies() {
        // 获取最近的指标数据
        Instant endTime = Instant.now();
        Instant startTime = endTime.minus(1, ChronoUnit.HOURS);
        
        List<ServerMetrics> recentMetrics = metricsRepository.findByTimeBetween(startTime, endTime);
        
        // 按服务器分组
        Map<Long, List<ServerMetrics>> metricsByServer = recentMetrics.stream()
                .collect(Collectors.groupingBy(ServerMetrics::getServerId));
        
        // 对每个服务器的指标进行异常检测
        for (Map.Entry<Long, List<ServerMetrics>> entry : metricsByServer.entrySet()) {
            Long serverId = entry.getKey();
            List<ServerMetrics> serverMetrics = entry.getValue();
            
            // 提取CPU使用率时间序列
            double[] cpuUsageValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getCpuUsage)
                    .toArray();
            
            // 提取内存使用率时间序列
            double[] memoryUsageValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getMemoryUsage)
                    .toArray();
            
            // 提取磁盘IO时间序列
            double[] diskIoValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getDiskIo)
                    .toArray();
            
            // 提取网络IO时间序列
            double[] networkIoValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getNetworkIo)
                    .toArray();
            
            // 使用模型进行异常检测
            AnomalyDetectionResult cpuResult = modelService.detectAnomaly("cpu_usage", cpuUsageValues);
            AnomalyDetectionResult memoryResult = modelService.detectAnomaly("memory_usage", memoryUsageValues);
            AnomalyDetectionResult diskIoResult = modelService.detectAnomaly("disk_io", diskIoValues);
            AnomalyDetectionResult networkIoResult = modelService.detectAnomaly("network_io", networkIoValues);
            
            // 处理检测结果
            processAnomalyResult(serverId, "CPU使用率", cpuResult);
            processAnomalyResult(serverId, "内存使用率", memoryResult);
            processAnomalyResult(serverId, "磁盘IO", diskIoResult);
            processAnomalyResult(serverId, "网络IO", networkIoResult);
        }
    }
    
    private void processAnomalyResult(Long serverId, String metricName, AnomalyDetectionResult result) {
        if (result.isAnomaly()) {
            // 创建告警
            String alertTitle = String.format("服务器 %d %s 异常", serverId, metricName);
            String alertDescription = String.format(
                    "检测到服务器 %d 的 %s 出现异常，异常分数: %.2f，阈值: %.2f",
                    serverId, metricName, result.getAnomalyScore(), result.getThreshold());
            
            alertService.createAlert(
                    AlertLevel.WARNING,
                    alertTitle,
                    alertDescription,
                    "aiops"
            );
            
            // 记录异常事件
            AnomalyEvent event = new AnomalyEvent();
            event.setServerId(serverId);
            event.setMetricName(metricName);
            event.setAnomalyScore(result.getAnomalyScore());
            event.setThreshold(result.getThreshold());
            event.setDetectedAt(Instant.now());
            event.setRawData(result.getRawData());
            
            anomalyEventRepository.save(event);
        }
    }
    
    @Scheduled(cron = "0 0 2 * * ?") // 每天凌晨2点执行
    public void trainModels() {
        // 获取过去30天的指标数据
        Instant endTime = Instant.now();
        Instant startTime = endTime.minus(30, ChronoUnit.DAYS);
        
        List<ServerMetrics> historicalMetrics = metricsRepository.findByTimeBetween(startTime, endTime);
        
        // 按服务器分组
        Map<Long, List<ServerMetrics>> metricsByServer = historicalMetrics.stream()
                .collect(Collectors.groupingBy(ServerMetrics::getServerId));
        
        // 对每个服务器的指标进行模型训练
        for (Map.Entry<Long, List<ServerMetrics>> entry : metricsByServer.entrySet()) {
            Long serverId = entry.getKey();
            List<ServerMetrics> serverMetrics = entry.getValue();
            
            // 提取CPU使用率时间序列
            double[] cpuUsageValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getCpuUsage)
                    .toArray();
            
            // 提取内存使用率时间序列
            double[] memoryUsageValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getMemoryUsage)
                    .toArray();
            
            // 提取磁盘IO时间序列
            double[] diskIoValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getDiskIo)
                    .toArray();
            
            // 提取网络IO时间序列
            double[] networkIoValues = serverMetrics.stream()
                    .mapToDouble(ServerMetrics::getNetworkIo)
                    .toArray();
            
            // 训练模型
            modelService.trainModel("cpu_usage_" + serverId, cpuUsageValues);
            modelService.trainModel("memory_usage_" + serverId, memoryUsageValues);
            modelService.trainModel("disk_io_" + serverId, diskIoValues);
            modelService.trainModel("network_io_" + serverId, networkIoValues);
        }
    }
}
```

#### 7.1.2 智能故障诊断

智能故障诊断是通过人工智能技术自动分析系统故障，快速定位故障根因，提供解决方案的技术。

```java
// 智能故障诊断服务示例
@Service
public class FaultDiagnosisService {
    
    private final AlertRepository alertRepository;
    private final MetricsRepository metricsRepository;
    private final LogRepository logRepository;
    private final KnowledgeBaseService knowledgeBaseService;
    
    @Autowired
    public FaultDiagnosisService(
            AlertRepository alertRepository,
            MetricsRepository metricsRepository,
            LogRepository logRepository,
            KnowledgeBaseService knowledgeBaseService) {
        this.alertRepository = alertRepository;
        this.metricsRepository = metricsRepository;
        this.logRepository = logRepository;
        this.knowledgeBaseService = knowledgeBaseService;
    }
    
    public DiagnosisResult diagnoseFault(Long alertId) {
        // 获取告警信息
        Alert alert = alertRepository.findById(alertId)
                .orElseThrow(() -> new ResourceNotFoundException("告警不存在: " + alertId));
        
        // 获取相关指标数据
        Instant alertTime = alert.getCreatedAt();
        Instant startTime = alertTime.minus(30, ChronoUnit.MINUTES);
        Instant endTime = alertTime.plus(10, ChronoUnit.MINUTES);
        
        List<ServerMetrics> metrics = metricsRepository.findByServerIdAndTimeBetween(
                alert.getServerId(), startTime, endTime);
        
        // 获取相关日志数据
        List<ServerLog> logs = logRepository.findByServerIdAndTimestampBetween(
                alert.getServerId(), startTime, endTime);
        
        // 提取特征
        Map<String, Object> features = extractFeatures(alert, metrics, logs);
        
        // 使用知识库进行故障诊断
        List<FaultPattern> matchedPatterns = knowledgeBaseService.matchFaultPatterns(features);
        
        // 生成诊断结果
        DiagnosisResult result = new DiagnosisResult();
        result.setAlertId(alertId);
        result.setDiagnosedAt(Instant.now());
        
        if (!matchedPatterns.isEmpty()) {
            // 按匹配度排序
            matchedPatterns.sort(Comparator.comparing(FaultPattern::getMatchScore).reversed());
            
            FaultPattern bestMatch = matchedPatterns.get(0);
            result.setRootCause(bestMatch.getRootCause());
            result.setConfidence(bestMatch.getMatchScore());
            result.setSolution(bestMatch.getSolution());
            result.setReferences(bestMatch.getReferences());
        } else {
            result.setRootCause("未能确定根因");
            result.setConfidence(0.0);
            result.setSolution("请手动分析系统日志和指标");
        }
        
        // 保存诊断结果
        return diagnosisResultRepository.save(result);
    }
    
    private Map<String, Object> extractFeatures(Alert alert, List<ServerMetrics> metrics, List<ServerLog> logs) {
        Map<String, Object> features = new HashMap<>();
        
        // 提取告警特征
        features.put("alert_type", alert.getType());
        features.put("alert_level", alert.getLevel());
        features.put("alert_message", alert.getMessage());
        
        // 提取指标特征
        if (!metrics.isEmpty()) {
            // 计算CPU使用率统计信息
            DoubleSummaryStatistics cpuStats = metrics.stream()
                    .mapToDouble(ServerMetrics::getCpuUsage)
                    .summaryStatistics();
            
            features.put("cpu_avg", cpuStats.getAverage());
            features.put("cpu_max", cpuStats.getMax());
            features.put("cpu_min", cpuStats.getMin());
            
            // 计算内存使用率统计信息
            DoubleSummaryStatistics memoryStats = metrics.stream()
                    .mapToDouble(ServerMetrics::getMemoryUsage)
                    .summaryStatistics();
            
            features.put("memory_avg", memoryStats.getAverage());
            features.put("memory_max", memoryStats.getMax());
            features.put("memory_min", memoryStats.getMin());
            
            // 计算磁盘IO统计信息
            DoubleSummaryStatistics diskIoStats = metrics.stream()
                    .mapToDouble(ServerMetrics::getDiskIo)
                    .summaryStatistics();
            
            features.put("disk_io_avg", diskIoStats.getAverage());
            features.put("disk_io_max", diskIoStats.getMax());
            
            // 计算网络IO统计信息
            DoubleSummaryStatistics networkIoStats = metrics.stream()
                    .mapToDouble(ServerMetrics::getNetworkIo)
                    .summaryStatistics();
            
            features.put("network_io_avg", networkIoStats.getAverage());
            features.put("network_io_max", networkIoStats.getMax());
        }
        
        // 提取日志特征
        if (!logs.isEmpty()) {
            // 提取错误日志数量
            long errorCount = logs.stream()
                    .filter(log -> log.getLevel().equals("ERROR"))
                    .count();
            
            features.put("error_log_count", errorCount);
            
            // 提取警告日志数量
            long warningCount = logs.stream()
                    .filter(log -> log.getLevel().equals("WARN"))
                    .count();
            
            features.put("warning_log_count", warningCount);
            
            // 提取常见错误模式
            List<String> errorMessages = logs.stream()
                    .filter(log -> log.getLevel().equals("ERROR"))
                    .map(ServerLog::getMessage)
                    .collect(Collectors.toList());
            
            features.put("error_messages", errorMessages);
            
            // 提取关键字出现频率
            Map<String, Long> keywordFrequency = new HashMap<>();
            List<String> keywords = Arrays.asList("exception", "error", "failed", "timeout", "rejected", "refused", "crash");
            
            for (String keyword : keywords) {
                long frequency = logs.stream()
                        .map(ServerLog::getMessage)
                        .filter(message -> message.toLowerCase().contains(keyword))
                        .count();
                
                keywordFrequency.put(keyword, frequency);
            }
            
            features.put("keyword_frequency", keywordFrequency);
        }
        
        return features;
    }
    
    @Scheduled(cron = "0 0 3 * * ?") // 每天凌晨3点执行
    public void updateKnowledgeBase() {
        // 获取过去30天的诊断结果
        Instant startTime = Instant.now().minus(30, ChronoUnit.DAYS);
        List<DiagnosisResult> recentResults = diagnosisResultRepository.findByDiagnosedAtAfter(startTime);
        
        // 按根因分组
        Map<String, List<DiagnosisResult>> resultsByRootCause = recentResults.stream()
                .collect(Collectors.groupingBy(DiagnosisResult::getRootCause));
        
        // 更新知识库
        for (Map.Entry<String, List<DiagnosisResult>> entry : resultsByRootCause.entrySet()) {
            String rootCause = entry.getKey();
            List<DiagnosisResult> results = entry.getValue();
            
            // 如果根因出现频率较高，更新知识库
            if (results.size() >= 5) {
                knowledgeBaseService.updateFaultPattern(rootCause, results);
            }
        }
    }
}
```

#### 7.1.3 预测性维护

预测性维护是通过分析历史数据和当前状态，预测系统可能出现的故障，提前采取维护措施，避免故障发生的技术。

```java
// 预测性维护服务示例
@Service
public class PredictiveMaintenanceService {
    
    private final ServerRepository serverRepository;
    private final MetricsRepository metricsRepository;
    private final MaintenanceTaskRepository taskRepository;
    private final ModelService modelService;
    private final NotificationService notificationService;
    
    @Autowired
    public PredictiveMaintenanceService(
            ServerRepository serverRepository,
            MetricsRepository metricsRepository,
            MaintenanceTaskRepository taskRepository,
            ModelService modelService,
            NotificationService notificationService) {
        this.serverRepository = serverRepository;
        this.metricsRepository = metricsRepository;
        this.taskRepository = taskRepository;
        this.modelService = modelService;
        this.notificationService = notificationService;
    }
    
    @Scheduled(cron = "0 0 1 * * ?") // 每天凌晨1点执行
    public void predictMaintenance() {
        // 获取所有服务器
        List<Server> servers = serverRepository.findAll();
        
        for (Server server : servers) {
            // 获取服务器最近30天的指标数据
            Instant endTime = Instant.now();
            Instant startTime = endTime.minus(30, ChronoUnit.DAYS);
            
            List<ServerMetrics> metrics = metricsRepository.findByServerIdAndTimeBetween(
                    server.getId(), startTime, endTime);
            
            if (metrics.isEmpty()) {
                continue;
            }
            
            // 提取特征
            Map<String, double[]> features = extractFeatures(metrics);
            
            // 预测磁盘故障概率
            double diskFailureProbability = modelService.predictDiskFailure(features);
            
            // 预测内存故障概率
            double memoryFailureProbability = modelService.predictMemoryFailure(features);
            
            // 预测CPU故障概率
            double cpuFailureProbability = modelService.predictCpuFailure(features);
            
            // 预测网络故障概率
            double networkFailureProbability = modelService.predictNetworkFailure(features);
            
            // 处理预测结果
            processPrediction(server, "磁盘", diskFailureProbability, 0.7);
            processPrediction(server, "内存", memoryFailureProbability, 0.7);
            processPrediction(server, "CPU", cpuFailureProbability, 0.7);
            processPrediction(server, "网络", networkFailureProbability, 0.7);
        }
    }
    
    private Map<String, double[]> extractFeatures(List<ServerMetrics> metrics) {
        Map<String, double[]> features = new HashMap<>();
        
        // 提取CPU使用率时间序列
        double[] cpuUsage = metrics.stream()
                .mapToDouble(ServerMetrics::getCpuUsage)
                .toArray();
        features.put("cpu_usage", cpuUsage);
        
        // 提取内存使用率时间序列
        double[] memoryUsage = metrics.stream()
                .mapToDouble(ServerMetrics::getMemoryUsage)
                .toArray();
        features.put("memory_usage", memoryUsage);
        
        // 提取磁盘使用率时间序列
        double[] diskUsage = metrics.stream()
                .mapToDouble(ServerMetrics::getDiskUsage)
                .toArray();
        features.put("disk_usage", diskUsage);
        
        // 提取磁盘IO时间序列
        double[] diskIo = metrics.stream()
                .mapToDouble(ServerMetrics::getDiskIo)
                .toArray();
        features.put("disk_io", diskIo);
        
        // 提取网络IO时间序列
        double[] networkIo = metrics.stream()
                .mapToDouble(ServerMetrics::getNetworkIo)
                .toArray();
        features.put("network_io", networkIo);
        
        // 提取系统负载时间序列
        double[] systemLoad = metrics.stream()
                .mapToDouble(ServerMetrics::getSystemLoad)
                .toArray();
        features.put("system_load", systemLoad);
        
        // 提取SMART数据（如果有）
        if (metrics.get(0).getSmartData() != null) {
            double[] smartReallocatedSectors = metrics.stream()
                    .mapToDouble(m -> m.getSmartData().getReallocatedSectors())
                    .toArray();
            features.put("smart_reallocated_sectors", smartReallocatedSectors);
            
            double[] smartPendingSectors = metrics.stream()
                    .mapToDouble(m -> m.getSmartData().getPendingSectors())
                    .toArray();
            features.put("smart_pending_sectors", smartPendingSectors);
            
            double[] smartUncorrectableSectors = metrics.stream()
                    .mapToDouble(m -> m.getSmartData().getUncorrectableSectors())
                    .toArray();
            features.put("smart_uncorrectable_sectors", smartUncorrectableSectors);
            
            double[] smartTemperature = metrics.stream()
                    .mapToDouble(m -> m.getSmartData().getTemperature())
                    .toArray();
            features.put("smart_temperature", smartTemperature);
        }
        
        return features;
    }
    
    private void processPrediction(Server server, String componentType, double failureProbability, double threshold) {
        if (failureProbability >= threshold) {
            // 创建维护任务
            MaintenanceTask task = new MaintenanceTask();
            task.setServer(server);
            task.setComponentType(componentType);
            task.setFailureProbability(failureProbability);
            task.setStatus(MaintenanceStatus.PENDING);
            task.setPredictedAt(Instant.now());
            task.setRecommendedAction(generateRecommendedAction(componentType, failureProbability));
            
            taskRepository.save(task);
            
            // 发送通知
            List<User> admins = userRepository.findByRole("ADMIN");
            for (User admin : admins) {
                notificationService.sendNotification(
                        admin.getUsername(),
                        "预测性维护建议",
                        String.format("服务器 %s 的 %s 组件可能即将发生故障，故障概率: %.2f%%",
                                server.getHostname(), componentType, failureProbability * 100),
                        NotificationType.MAINTENANCE_RECOMMENDATION,
                        Map.of("serverId", server.getId().toString(),
                               "componentType", componentType,
                               "failureProbability", String.valueOf(failureProbability))
                );
            }
        }
    }
    
    private String generateRecommendedAction(String componentType, double failureProbability) {
        switch (componentType) {
            case "磁盘":
                return "建议备份数据并检查磁盘健康状态，考虑更换磁盘";
            case "内存":
                return "建议运行内存诊断工具，考虑清理内存插槽或更换内存模块";
            case "CPU":
                return "建议检查CPU温度和散热系统，考虑清理散热器或更换散热风扇";
            case "网络":
                return "建议检查网络连接和网络设备，考虑更换网络适配器或网络线缆";
            default:
                return "建议进行系统全面检查";
        }
    }
    
    @Scheduled(cron = "0 0 2 * * ?") // 每天凌晨2点执行
    public void trainModels() {
        // 获取过去180天的指标数据和维护记录
        Instant endTime = Instant.now();
        Instant startTime = endTime.minus(180, Chro
让我继续完成自动化运维平台设计的内容：

### 7.1 智能化运维（续）

#### 7.1.3 预测性维护（续）

```java
    @Scheduled(cron = "0 0 2 * * ?") // 每天凌晨2点执行
    public void trainModels() {
        // 获取过去180天的指标数据和维护记录
        Instant endTime = Instant.now();
        Instant startTime = endTime.minus(180, ChronoUnit.DAYS);
        
        List<MaintenanceRecord> maintenanceRecords = maintenanceRecordRepository.findByPerformedAtBetween(
                startTime, endTime);
        
        // 按服务器分组
        Map<Long, List<MaintenanceRecord>> recordsByServer = maintenanceRecords.stream()
                .collect(Collectors.groupingBy(record -> record.getServer().getId()));
        
        // 训练模型
        for (Map.Entry<Long, List<MaintenanceRecord>> entry : recordsByServer.entrySet()) {
            Long serverId = entry.getKey();
            List<MaintenanceRecord> records = entry.getValue();
            
            // 获取服务器指标数据
            List<ServerMetrics> metrics = metricsRepository.findByServerIdAndTimeBetween(
                    serverId, startTime, endTime);
            
            if (metrics.isEmpty()) {
                continue;
            }
            
            // 准备训练数据
            List<TrainingData> trainingDataList = prepareTrainingData(metrics, records);
            
            // 训练磁盘故障预测模型
            modelService.trainDiskFailureModel(
                    serverId,
                    trainingDataList.stream()
                            .filter(data -> data.getComponentType().equals("磁盘"))
                            .collect(Collectors.toList())
            );
            
            // 训练内存故障预测模型
            modelService.trainMemoryFailureModel(
                    serverId,
                    trainingDataList.stream()
                            .filter(data -> data.getComponentType().equals("内存"))
                            .collect(Collectors.toList())
            );
            
            // 训练CPU故障预测模型
            modelService.trainCpuFailureModel(
                    serverId,
                    trainingDataList.stream()
                            .filter(data -> data.getComponentType().equals("CPU"))
                            .collect(Collectors.toList())
            );
            
            // 训练网络故障预测模型
            modelService.trainNetworkFailureModel(
                    serverId,
                    trainingDataList.stream()
                            .filter(data -> data.getComponentType().equals("网络"))
                            .collect(Collectors.toList())
            );
        }
    }
    
    private List<TrainingData> prepareTrainingData(List<ServerMetrics> metrics, List<MaintenanceRecord> records) {
        List<TrainingData> trainingDataList = new ArrayList<>();
        
        // 将维护记录按时间排序
        records.sort(Comparator.comparing(MaintenanceRecord::getPerformedAt));
        
        // 对每个维护记录，提取之前30天的指标数据作为特征
        for (MaintenanceRecord record : records) {
            Instant recordTime = record.getPerformedAt();
            Instant featureStartTime = recordTime.minus(30, ChronoUnit.DAYS);
            
            List<ServerMetrics> featureMetrics = metrics.stream()
                    .filter(m -> m.getTimestamp().isAfter(featureStartTime) && m.getTimestamp().isBefore(recordTime))
                    .collect(Collectors.toList());
            
            if (featureMetrics.isEmpty()) {
                continue;
            }
            
            // 提取特征
            Map<String, double[]> features = extractFeatures(featureMetrics);
            
            // 创建训练数据
            TrainingData trainingData = new TrainingData();
            trainingData.setFeatures(features);
            trainingData.setComponentType(record.getComponentType());
            trainingData.setFailureType(record.getFailureType());
            trainingData.setLabel(1.0); // 1表示发生故障
            
            trainingDataList.add(trainingData);
        }
        
        // 添加负样本（未发生故障的时间段）
        addNegativeSamples(metrics, records, trainingDataList);
        
        return trainingDataList;
    }
    
    private void addNegativeSamples(List<ServerMetrics> metrics, List<MaintenanceRecord> records, List<TrainingData> trainingDataList) {
        // 将指标数据按时间排序
        metrics.sort(Comparator.comparing(ServerMetrics::getTimestamp));
        
        // 计算指标数据的时间范围
        Instant dataStartTime = metrics.get(0).getTimestamp();
        Instant dataEndTime = metrics.get(metrics.size() - 1).getTimestamp();
        
        // 将时间范围分成30天的窗口
        List<Pair<Instant, Instant>> timeWindows = new ArrayList<>();
        Instant windowStart = dataStartTime;
        
        while (windowStart.isBefore(dataEndTime)) {
            Instant windowEnd = windowStart.plus(30, ChronoUnit.DAYS);
            if (windowEnd.isAfter(dataEndTime)) {
                windowEnd = dataEndTime;
            }
            
            timeWindows.add(Pair.of(windowStart, windowEnd));
            windowStart = windowEnd;
        }
        
        // 对每个时间窗口，检查是否有维护记录
        for (Pair<Instant, Instant> window : timeWindows) {
            Instant windowStart = window.getFirst();
            Instant windowEnd = window.getSecond();
            
            // 检查窗口期内是否有维护记录
            boolean hasMaintenanceRecord = records.stream()
                    .anyMatch(r -> r.getPerformedAt().isAfter(windowStart) && r.getPerformedAt().isBefore(windowEnd));
            
            // 如果没有维护记录，添加负样本
            if (!hasMaintenanceRecord) {
                List<ServerMetrics> windowMetrics = metrics.stream()
                        .filter(m -> m.getTimestamp().isAfter(windowStart) && m.getTimestamp().isBefore(windowEnd))
                        .collect(Collectors.toList());
                
                if (windowMetrics.isEmpty()) {
                    continue;
                }
                
                // 提取特征
                Map<String, double[]> features = extractFeatures(windowMetrics);
                
                // 为每种组件类型添加负样本
                for (String componentType : Arrays.asList("磁盘", "内存", "CPU", "网络")) {
                    TrainingData trainingData = new TrainingData();
                    trainingData.setFeatures(features);
                    trainingData.setComponentType(componentType);
                    trainingData.setFailureType("无故障");
                    trainingData.setLabel(0.0); // 0表示未发生故障
                    
                    trainingDataList.add(trainingData);
                }
            }
        }
    }
}
```

### 7.2 云原生运维

云原生运维是基于云计算和容器技术的运维实践，通过容器化、微服务化和自动化，实现更高效、更灵活的IT运维。

#### 7.2.1 容器编排

容器编排是管理容器化应用的生命周期，包括部署、扩展、网络、存储等方面的技术。

```java
// Kubernetes集成服务示例
@Service
public class KubernetesService {
    
    private final KubernetesClient kubernetesClient;
    private final ClusterRepository clusterRepository;
    private final DeploymentRepository deploymentRepository;
    private final AlertService alertService;
    
    @Autowired
    public KubernetesService(
            KubernetesClient kubernetesClient,
            ClusterRepository clusterRepository,
            DeploymentRepository deploymentRepository,
            AlertService alertService) {
        this.kubernetesClient = kubernetesClient;
        this.clusterRepository = clusterRepository;
        this.deploymentRepository = deploymentRepository;
        this.alertService = alertService;
    }
    
    public List<KubernetesCluster> getAllClusters() {
        return clusterRepository.findAll();
    }
    
    public KubernetesCluster getClusterById(Long clusterId) {
        return clusterRepository.findById(clusterId)
                .orElseThrow(() -> new ResourceNotFoundException("集群不存在: " + clusterId));
    }
    
    public KubernetesCluster addCluster(KubernetesClusterDTO clusterDTO) {
        // 验证集群连接
        try {
            Config config = new ConfigBuilder()
                    .withMasterUrl(clusterDTO.getApiServerUrl())
                    .withOauthToken(clusterDTO.getToken())
                    .withTrustCerts(true)
                    .build();
            
            try (KubernetesClient testClient = new DefaultKubernetesClient(config)) {
                testClient.namespaces().list();
            }
        } catch (Exception e) {
            throw new InvalidOperationException("无法连接到Kubernetes集群: " + e.getMessage());
        }
        
        KubernetesCluster cluster = new KubernetesCluster();
        cluster.setName(clusterDTO.getName());
        cluster.setApiServerUrl(clusterDTO.getApiServerUrl());
        cluster.setToken(clusterDTO.getToken());
        cluster.setDescription(clusterDTO.getDescription());
        cluster.setCreatedAt(Instant.now());
        
        return clusterRepository.save(cluster);
    }
    
    public void deleteCluster(Long clusterId) {
        KubernetesCluster cluster = clusterRepository.findById(clusterId)
                .orElseThrow(() -> new ResourceNotFoundException("集群不存在: " + clusterId));
        
        // 检查是否有关联的部署
        List<KubernetesDeployment> deployments = deploymentRepository.findByClusterId(clusterId);
        if (!deployments.isEmpty()) {
            throw new InvalidOperationException("无法删除集群，存在关联的部署");
        }
        
        clusterRepository.delete(cluster);
    }
    
    public List<NamespaceDTO> getNamespaces(Long clusterId) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            return client.namespaces().list().getItems().stream()
                    .map(ns -> new NamespaceDTO(
                            ns.getMetadata().getName(),
                            ns.getMetadata().getCreationTimestamp(),
                            ns.getStatus().getPhase()
                    ))
                    .collect(Collectors.toList());
        }
    }
    
    public NamespaceDTO createNamespace(Long clusterId, String namespaceName) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            Namespace namespace = new NamespaceBuilder()
                    .withNewMetadata()
                    .withName(namespaceName)
                    .endMetadata()
                    .build();
            
            Namespace createdNamespace = client.namespaces().create(namespace);
            
            return new NamespaceDTO(
                    createdNamespace.getMetadata().getName(),
                    createdNamespace.getMetadata().getCreationTimestamp(),
                    createdNamespace.getStatus().getPhase()
            );
        }
    }
    
    public void deleteNamespace(Long clusterId, String namespaceName) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            client.namespaces().withName(namespaceName).delete();
        }
    }
    
    public List<DeploymentDTO> getDeployments(Long clusterId, String namespace) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            return client.apps().deployments().inNamespace(namespace).list().getItems().stream()
                    .map(deployment -> {
                        String name = deployment.getMetadata().getName();
                        Integer replicas = deployment.getSpec().getReplicas();
                        Integer availableReplicas = deployment.getStatus().getAvailableReplicas();
                        
                        return new DeploymentDTO(
                                name,
                                namespace,
                                replicas,
                                availableReplicas,
                                deployment.getMetadata().getCreationTimestamp()
                        );
                    })
                    .collect(Collectors.toList());
        }
    }
    
    public DeploymentDTO createDeployment(Long clusterId, DeploymentCreateDTO deploymentDTO) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            // 创建Deployment
            Deployment deployment = new DeploymentBuilder()
                    .withNewMetadata()
                    .withName(deploymentDTO.getName())
                    .endMetadata()
                    .withNewSpec()
                    .withReplicas(deploymentDTO.getReplicas())
                    .withNewSelector()
                    .withMatchLabels(Collections.singletonMap("app", deploymentDTO.getName()))
                    .endSelector()
                    .withNewTemplate()
                    .withNewMetadata()
                    .withLabels(Collections.singletonMap("app", deploymentDTO.getName()))
                    .endMetadata()
                    .withNewSpec()
                    .addNewContainer()
                    .withName(deploymentDTO.getName())
                    .withImage(deploymentDTO.getImage())
                    .withPorts(deploymentDTO.getPorts().stream()
                            .map(port -> new ContainerPortBuilder()
                                    .withContainerPort(port.getPort())
                                    .withProtocol(port.getProtocol())
                                    .build())
                            .collect(Collectors.toList()))
                    .withEnv(deploymentDTO.getEnvironmentVariables().stream()
                            .map(env -> new EnvVarBuilder()
                                    .withName(env.getName())
                                    .withValue(env.getValue())
                                    .build())
                            .collect(Collectors.toList()))
                    .withResources(new ResourceRequirementsBuilder()
                            .withRequests(Map.of(
                                    "cpu", new Quantity(deploymentDTO.getCpuRequest()),
                                    "memory", new Quantity(deploymentDTO.getMemoryRequest())
                            ))
                            .withLimits(Map.of(
                                    "cpu", new Quantity(deploymentDTO.getCpuLimit()),
                                    "memory", new Quantity(deploymentDTO.getMemoryLimit())
                            ))
                            .build())
                    .endContainer()
                    .endSpec()
                    .endTemplate()
                    .endSpec()
                    .build();
            
            Deployment createdDeployment = client.apps().deployments()
                    .inNamespace(deploymentDTO.getNamespace())
                    .create(deployment);
            
            // 保存部署记录
            KubernetesDeployment deploymentRecord = new KubernetesDeployment();
            deploymentRecord.setCluster(cluster);
            deploymentRecord.setName(deploymentDTO.getName());
            deploymentRecord.setNamespace(deploymentDTO.getNamespace());
            deploymentRecord.setImage(deploymentDTO.getImage());
            deploymentRecord.setReplicas(deploymentDTO.getReplicas());
            deploymentRecord.setCreatedAt(Instant.now());
            
            deploymentRepository.save(deploymentRecord);
            
            return new DeploymentDTO(
                    createdDeployment.getMetadata().getName(),
                    createdDeployment.getMetadata().getNamespace(),
                    createdDeployment.getSpec().getReplicas(),
                    createdDeployment.getStatus().getAvailableReplicas(),
                    createdDeployment.getMetadata().getCreationTimestamp()
            );
        }
    }
    
    public void deleteDeployment(Long clusterId, String namespace, String name) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            client.apps().deployments().inNamespace(namespace).withName(name).delete();
            
            // 删除部署记录
            deploymentRepository.deleteByClusterIdAndNamespaceAndName(clusterId, namespace, name);
        }
    }
    
    public void scaleDeployment(Long clusterId, String namespace, String name, int replicas) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            client.apps().deployments().inNamespace(namespace).withName(name)
                    .edit(d -> new DeploymentBuilder(d).editSpec().withReplicas(replicas).endSpec().build());
            
            // 更新部署记录
            KubernetesDeployment deployment = deploymentRepository.findByClusterIdAndNamespaceAndName(
                    clusterId, namespace, name);
            
            if (deployment != null) {
                deployment.setReplicas(replicas);
                deployment.setUpdatedAt(Instant.now());
                deploymentRepository.save(deployment);
            }
        }
    }
    
    public List<PodDTO> getPods(Long clusterId, String namespace, String deploymentName) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            return client.pods().inNamespace(namespace)
                    .withLabel("app", deploymentName)
                    .list().getItems().stream()
                    .map(pod -> {
                        String name = pod.getMetadata().getName();
                        String phase = pod.getStatus().getPhase();
                        String nodeName = pod.getSpec().getNodeName();
                        String ip = pod.getStatus().getPodIP();
                        
                        return new PodDTO(
                                name,
                                namespace,
                                phase,
                                nodeName,
                                ip,
                                pod.getMetadata().getCreationTimestamp()
                        );
                    })
                    .collect(Collectors.toList());
        }
    }
    
    public String getPodLogs(Long clusterId, String namespace, String podName) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            return client.pods().inNamespace(namespace).withName(podName).getLog();
        }
    }
    
    public List<ServiceDTO> getServices(Long clusterId, String namespace) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            return client.services().inNamespace(namespace).list().getItems().stream()
                    .map(service -> {
                        String name = service.getMetadata().getName();
                        String type = service.getSpec().getType();
                        String clusterIP = service.getSpec().getClusterIP();
                        List<ServicePortDTO> ports = service.getSpec().getPorts().stream()
                                .map(port -> new ServicePortDTO(
                                        port.getName(),
                                        port.getPort(),
                                        port.getTargetPort().getIntVal(),
                                        port.getProtocol()
                                ))
                                .collect(Collectors.toList());
                        
                        return new ServiceDTO(
                                name,
                                namespace,
                                type,
                                clusterIP,
                                ports,
                                service.getMetadata().getCreationTimestamp()
                        );
                    })
                    .collect(Collectors.toList());
        }
    }
    
    public ServiceDTO createService(Long clusterId, ServiceCreateDTO serviceDTO) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            Service service = new ServiceBuilder()
                    .withNewMetadata()
                    .withName(serviceDTO.getName())
                    .endMetadata()
                    .withNewSpec()
                    .withType(serviceDTO.getType())
                    .withSelector(Collections.singletonMap("app", serviceDTO.getSelector()))
                    .withPorts(serviceDTO.getPorts().stream()
                            .map(port -> new ServicePortBuilder()
                                    .withName(port.getName())
                                    .withPort(port.getPort())
                                    .withNewTargetPort(port.getTargetPort())
                                    .withProtocol(port.getProtocol())
                                    .build())
                            .collect(Collectors.toList()))
                    .endSpec()
                    .build();
            
            Service createdService = client.services()
                    .inNamespace(serviceDTO.getNamespace())
                    .create(service);
            
            return new ServiceDTO(
                    createdService.getMetadata().getName(),
                    createdService.getMetadata().getNamespace(),
                    createdService.getSpec().getType(),
                    createdService.getSpec().getClusterIP(),
                    createdService.getSpec().getPorts().stream()
                            .map(port -> new ServicePortDTO(
                                    port.getName(),
                                    port.getPort(),
                                    port.getTargetPort().getIntVal(),
                                    port.getProtocol()
                            ))
                            .collect(Collectors.toList()),
                    createdService.getMetadata().getCreationTimestamp()
            );
        }
    }
    
    public void deleteService(Long clusterId, String namespace, String name) {
        KubernetesCluster cluster = getClusterById(clusterId);
        
        try (KubernetesClient client = createClient(cluster)) {
            client.services().inNamespace(namespace).withName(name).delete();
        }
    }
    
    @Scheduled(fixedRate = 60000) // 每分钟执行一次
    public void monitorClusters() {
        List<KubernetesCluster> clusters = clusterRepository.findAll();
        
        for (KubernetesCluster cluster : clusters) {
            try (KubernetesClient client = createClient(cluster)) {
                // 检查节点状态
                client.nodes().list().getItems().forEach(node -> {
                    String nodeName = node.getMetadata().getName();
                    List<NodeCondition> conditions = node.getStatus().getConditions();
                    
                    // 检查节点是否就绪
                    boolean ready = conditions.stream()
                            .filter(c -> c.getType().equals("Ready"))
                            .anyMatch(c -> c.getStatus().equals("True"));
                    
                    if (!ready) {
                        alertService.createAlert(
                                AlertLevel.WARNING,
                                "Kubernetes节点未就绪",
                                String.format("集群 %s 中的节点 %s 未就绪", cluster.getName(), nodeName),
                                "kubernetes"
                        );
                    }
                });
                
                // 检查Pod状态
                client.pods().inAnyNamespace().list().getItems().forEach(pod -> {
                    String podName = pod.getMetadata().getName();
                    String namespace = pod.getMetadata().getNamespace();
                    String phase = pod.getStatus().getPhase();
                    
                    if (phase.equals("Failed") || phase.equals("Unknown")) {
                        alertService.createAlert(
                                AlertLevel.WARNING,
                                "Kubernetes Pod状态异常",
                                String.format("集群 %s 中的Pod %s/%s 状态为 %s",
                                        cluster.getName(), namespace, podName, phase),
                                "kubernetes"
                        );
                    }
                    
                    // 检查容器状态
                    List<ContainerStatus> containerStatuses = pod.getStatus().getContainerStatuses();
                    if (containerStatuses != null) {
                        for (ContainerStatus status : containerStatuses) {
                            if (status.getState().getWaiting() != null) {
                                String reason = status.getState().getWaiting().getReason();
                                if (reason.equals("CrashLoopBackOff") || reason.equals("ImagePullBackOff")) {
                                    alertService.createAlert(
                                            AlertLevel.WARNING,
                                            "Kubernetes容器状态异常",
                                            String.format("集群 %s 中的Pod %s/%s 的容器 %s 状态异常: %s",
                                                    cluster.getName(), namespace, podName,
                                                    status.getName(), reason),
                                            "kubernetes"
                                    );
                                }
                            }
                        }
                    }
                });
                
                // 检查Deployment状态
                client.apps().deployments().inAnyNamespace().list().getItems().forEach(deployment -> {
                    String deploymentName = deployment.getMetadata().getName();
                    String namespace = deployment.getMetadata().getNamespace();
                    Integer replicas = deployment.getSpec().getReplicas();
                    Integer availableReplicas = deployment.getStatus().getAvailableReplicas();
                    
                    if (availableReplicas == null || availableReplicas < replicas) {
                        alertService.createAlert(
                                AlertLevel.WARNING,
                                "Kubernetes Deployment副本不足",
                                String.format("集群 %s 中的Deployment %s/%s 可用副本数 %d/%d",
                                        cluster.getName(), namespace, deploymentName,
                                        availableReplicas == null ? 0 : availableReplicas, replicas),
                                "kubernetes"
                        );
                    }
                });
            } catch (Exception e) {
                alertService.createAlert(
                        AlertLevel.ERROR,
                        "Kubernetes集群连接异常",
                        String.format("无法连接到集群 %s: %s", cluster.getName(), e.getMessage()),
                        "kubernetes"
                );
            }
        }
    }
    
    private KubernetesClient createClient(KubernetesCluster cluster) {
        Config config = new ConfigBuilder()
                .withMasterUrl(cluster.getApiServerUrl())
                .withOauthToken(cluster.getToken())
                .withTrustCerts(true)
                .build();
        
        return new DefaultKubernetesClient(config);
    }
}
```

#### 7.2.2 服务网格

服务网格是一种基础设施层，用于处理服务间通信，提供服务发现、负载均衡、故障恢复、指标收集和安全等功能。

```java
// Istio集成服务示例
@Service
public class IstioService {
    
    private final KubernetesService kubernetesService;
    
    @Autowired
    public IstioService(KubernetesService kubernetesService) {
        this.kubernetesService = kubernetesService;
    }
    
    public List<VirtualServiceDTO> getVirtualServices(Long clusterId, String namespace) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            CustomResourceDefinitionContext crdContext = new CustomResourceDefinitionContext.Builder()
                    .withGroup("networking.istio.io")
                    .withVersion("v1beta1")
                    .withScope("Namespaced")
                    .withPlural("virtualservices")
                    .build();
            
            List<Map<String, Object>> virtualServices = client.customResource(crdContext)
                    .list(namespace)
                    .get("items", new TypeReference<List<Map<String, Object>>>() {});
            
            return virtualServices.stream()
                    .map(this::mapToVirtualServiceDTO)
                    .collect(Collectors.toList());
        } finally {
            client.close();
        }
    }
    
    public VirtualServiceDTO createVirtualService(Long clusterId, VirtualServiceCreateDTO dto) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            CustomResourceDefinitionContext crdContext = new CustomResourceDefinitionContext.Builder()
                    .withGroup("networking.istio.io")
                    .withVersion("v1beta1")
                    .withScope("Namespaced")
                    .withPlural("virtualservices")
                    .build();
            
            Map<String, Object> virtualService = new HashMap<>();
            Map<String, Object> metadata = new HashMap<>();
            metadata.put("name", dto.getName());
            virtualService.put("apiVersion", "networking.istio.io/v1beta1");
            virtualService.put("kind", "VirtualService");
            virtualService.put("metadata", metadata);
            
            Map<String, Object> spec = new HashMap<>();
            spec.put("hosts", dto.getHosts());
            spec.put("gateways", dto.getGateways());
            
            List<Map<String, Object>> httpRoutes = new ArrayList<>();
            for (HttpRouteDTO routeDTO : dto.getHttpRoutes()) {
                Map<String, Object> route = new HashMap<>();
                
                List<Map<String, Object>> destinations = new ArrayList<>();
                for (DestinationDTO destDTO : routeDTO.getDestinations()) {
                    Map<String, Object> destination = new HashMap<>();
                    Map<String, Object> dest = new HashMap<>();
                    dest.put("host", destDTO.getHost());
                    dest.put("subset", destDTO.getSubset());
                    dest.put("port", Map.of("number", destDTO.getPort()));
                    destination.put("destination", dest);
                    destination.put("weight", destDTO.getWeight());
                    destinations.add(destination);
                }
                
                route.put("route", destinations);
                
                if (routeDTO.getMatch() != null && !routeDTO.getMatch().isEmpty()) {
                    route.put("match", routeDTO.getMatch());
                }
                
                if (routeDTO.getRetries() != null) {
                    route.put("retries", routeDTO.getRetries());
                }
                
                if (routeDTO.getTimeout() != null) {
                    route.put("timeout", routeDTO.getTimeout());
                }
                
                httpRoutes.add(route);
            }
            
            spec.put("http", httpRoutes);
            virtualService.put("spec", spec);
            
            Map<String, Object> created = client.customResource(crdContext)
                    .create(dto.getNamespace(), virtualService);
            
            return mapToVirtualServiceDTO(created);
让我继续完成自动化运维平台设计的内容：

### 7.2 云原生运维（续）

#### 7.2.2 服务网格（续）

```java
            return mapToVirtualServiceDTO(created);
        } finally {
            client.close();
        }
    }
    
    public void deleteVirtualService(Long clusterId, String namespace, String name) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            CustomResourceDefinitionContext crdContext = new CustomResourceDefinitionContext.Builder()
                    .withGroup("networking.istio.io")
                    .withVersion("v1beta1")
                    .withScope("Namespaced")
                    .withPlural("virtualservices")
                    .build();
            
            client.customResource(crdContext).delete(namespace, name);
        } finally {
            client.close();
        }
    }
    
    public List<DestinationRuleDTO> getDestinationRules(Long clusterId, String namespace) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            CustomResourceDefinitionContext crdContext = new CustomResourceDefinitionContext.Builder()
                    .withGroup("networking.istio.io")
                    .withVersion("v1beta1")
                    .withScope("Namespaced")
                    .withPlural("destinationrules")
                    .build();
            
            List<Map<String, Object>> destinationRules = client.customResource(crdContext)
                    .list(namespace)
                    .get("items", new TypeReference<List<Map<String, Object>>>() {});
            
            return destinationRules.stream()
                    .map(this::mapToDestinationRuleDTO)
                    .collect(Collectors.toList());
        } finally {
            client.close();
        }
    }
    
    public DestinationRuleDTO createDestinationRule(Long clusterId, DestinationRuleCreateDTO dto) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            CustomResourceDefinitionContext crdContext = new CustomResourceDefinitionContext.Builder()
                    .withGroup("networking.istio.io")
                    .withVersion("v1beta1")
                    .withScope("Namespaced")
                    .withPlural("destinationrules")
                    .build();
            
            Map<String, Object> destinationRule = new HashMap<>();
            Map<String, Object> metadata = new HashMap<>();
            metadata.put("name", dto.getName());
            destinationRule.put("apiVersion", "networking.istio.io/v1beta1");
            destinationRule.put("kind", "DestinationRule");
            destinationRule.put("metadata", metadata);
            
            Map<String, Object> spec = new HashMap<>();
            spec.put("host", dto.getHost());
            
            if (dto.getTrafficPolicy() != null) {
                spec.put("trafficPolicy", dto.getTrafficPolicy());
            }
            
            List<Map<String, Object>> subsets = new ArrayList<>();
            for (SubsetDTO subsetDTO : dto.getSubsets()) {
                Map<String, Object> subset = new HashMap<>();
                subset.put("name", subsetDTO.getName());
                subset.put("labels", subsetDTO.getLabels());
                
                if (subsetDTO.getTrafficPolicy() != null) {
                    subset.put("trafficPolicy", subsetDTO.getTrafficPolicy());
                }
                
                subsets.add(subset);
            }
            
            spec.put("subsets", subsets);
            destinationRule.put("spec", spec);
            
            Map<String, Object> created = client.customResource(crdContext)
                    .create(dto.getNamespace(), destinationRule);
            
            return mapToDestinationRuleDTO(created);
        } finally {
            client.close();
        }
    }
    
    public void deleteDestinationRule(Long clusterId, String namespace, String name) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            CustomResourceDefinitionContext crdContext = new CustomResourceDefinitionContext.Builder()
                    .withGroup("networking.istio.io")
                    .withVersion("v1beta1")
                    .withScope("Namespaced")
                    .withPlural("destinationrules")
                    .build();
            
            client.customResource(crdContext).delete(namespace, name);
        } finally {
            client.close();
        }
    }
    
    public Map<String, Object> getServiceMetrics(Long clusterId, String namespace, String serviceName, String interval) {
        KubernetesClient client = kubernetesService.createClient(clusterId);
        
        try {
            // 获取Prometheus服务地址
            Service prometheusService = client.services()
                    .inNamespace("istio-system")
                    .withName("prometheus")
                    .get();
            
            if (prometheusService == null) {
                throw new ResourceNotFoundException("Prometheus服务未找到");
            }
            
            String prometheusUrl = String.format("http://%s:%d",
                    prometheusService.getSpec().getClusterIP(),
                    prometheusService.getSpec().getPorts().get(0).getPort());
            
            // 构建Prometheus查询
            Map<String, Object> metrics = new HashMap<>();
            
            // 请求速率
            String requestRateQuery = String.format(
                    "sum(rate(istio_requests_total{destination_service=\"%s.%s.svc.cluster.local\"}[%s])) by (reporter)",
                    serviceName, namespace, interval);
            metrics.put("requestRate", queryPrometheus(prometheusUrl, requestRateQuery));
            
            // 错误率
            String errorRateQuery = String.format(
                    "sum(rate(istio_requests_total{destination_service=\"%s.%s.svc.cluster.local\",response_code=~\"5.*\"}[%s])) by (reporter) / sum(rate(istio_requests_total{destination_service=\"%s.%s.svc.cluster.local\"}[%s])) by (reporter)",
                    serviceName, namespace, interval, serviceName, namespace, interval);
            metrics.put("errorRate", queryPrometheus(prometheusUrl, errorRateQuery));
            
            // P95延迟
            String p95LatencyQuery = String.format(
                    "histogram_quantile(0.95, sum(rate(istio_request_duration_milliseconds_bucket{destination_service=\"%s.%s.svc.cluster.local\"}[%s])) by (le, reporter))",
                    serviceName, namespace, interval);
            metrics.put("p95Latency", queryPrometheus(prometheusUrl, p95LatencyQuery));
            
            // TCP接收字节率
            String tcpReceivedQuery = String.format(
                    "sum(rate(istio_tcp_received_bytes_total{destination_service=\"%s.%s.svc.cluster.local\"}[%s])) by (reporter)",
                    serviceName, namespace, interval);
            metrics.put("tcpReceived", queryPrometheus(prometheusUrl, tcpReceivedQuery));
            
            // TCP发送字节率
            String tcpSentQuery = String.format(
                    "sum(rate(istio_tcp_sent_bytes_total{destination_service=\"%s.%s.svc.cluster.local\"}[%s])) by (reporter)",
                    serviceName, namespace, interval);
            metrics.put("tcpSent", queryPrometheus(prometheusUrl, tcpSentQuery));
            
            return metrics;
        } finally {
            client.close();
        }
    }
    
    private Object queryPrometheus(String prometheusUrl, String query) {
        RestTemplate restTemplate = new RestTemplate();
        String url = String.format("%s/api/v1/query?query=%s", prometheusUrl, URLEncoder.encode(query, StandardCharsets.UTF_8));
        
        ResponseEntity<Map<String, Object>> response = restTemplate.exchange(
                url,
                HttpMethod.GET,
                null,
                new ParameterizedTypeReference<Map<String, Object>>() {}
        );
        
        Map<String, Object> body = response.getBody();
        if (body != null && body.get("status").equals("success")) {
            return body.get("data");
        }
        
        return null;
    }
    
    private VirtualServiceDTO mapToVirtualServiceDTO(Map<String, Object> virtualService) {
        Map<String, Object> metadata = (Map<String, Object>) virtualService.get("metadata");
        Map<String, Object> spec = (Map<String, Object>) virtualService.get("spec");
        
        VirtualServiceDTO dto = new VirtualServiceDTO();
        dto.setName((String) metadata.get("name"));
        dto.setNamespace((String) metadata.get("namespace"));
        dto.setCreationTimestamp((String) metadata.get("creationTimestamp"));
        
        dto.setHosts((List<String>) spec.get("hosts"));
        dto.setGateways((List<String>) spec.get("gateways"));
        
        List<Map<String, Object>> http = (List<Map<String, Object>>) spec.get("http");
        if (http != null) {
            List<HttpRouteDTO> httpRoutes = new ArrayList<>();
            
            for (Map<String, Object> route : http) {
                HttpRouteDTO httpRouteDTO = new HttpRouteDTO();
                
                List<Map<String, Object>> destinations = (List<Map<String, Object>>) route.get("route");
                if (destinations != null) {
                    List<DestinationDTO> destinationDTOs = new ArrayList<>();
                    
                    for (Map<String, Object> destination : destinations) {
                        Map<String, Object> dest = (Map<String, Object>) destination.get("destination");
                        Integer weight = (Integer) destination.get("weight");
                        
                        DestinationDTO destinationDTO = new DestinationDTO();
                        destinationDTO.setHost((String) dest.get("host"));
                        destinationDTO.setSubset((String) dest.get("subset"));
                        
                        Map<String, Object> port = (Map<String, Object>) dest.get("port");
                        if (port != null) {
                            destinationDTO.setPort(((Number) port.get("number")).intValue());
                        }
                        
                        destinationDTO.setWeight(weight);
                        destinationDTOs.add(destinationDTO);
                    }
                    
                    httpRouteDTO.setDestinations(destinationDTOs);
                }
                
                httpRouteDTO.setMatch((List<Map<String, Object>>) route.get("match"));
                httpRouteDTO.setRetries((Map<String, Object>) route.get("retries"));
                httpRouteDTO.setTimeout((String) route.get("timeout"));
                
                httpRoutes.add(httpRouteDTO);
            }
            
            dto.setHttpRoutes(httpRoutes);
        }
        
        return dto;
    }
    
    private DestinationRuleDTO mapToDestinationRuleDTO(Map<String, Object> destinationRule) {
        Map<String, Object> metadata = (Map<String, Object>) destinationRule.get("metadata");
        Map<String, Object> spec = (Map<String, Object>) destinationRule.get("spec");
        
        DestinationRuleDTO dto = new DestinationRuleDTO();
        dto.setName((String) metadata.get("name"));
        dto.setNamespace((String) metadata.get("namespace"));
        dto.setCreationTimestamp((String) metadata.get("creationTimestamp"));
        
        dto.setHost((String) spec.get("host"));
        dto.setTrafficPolicy((Map<String, Object>) spec.get("trafficPolicy"));
        
        List<Map<String, Object>> subsets = (List<Map<String, Object>>) spec.get("subsets");
        if (subsets != null) {
            List<SubsetDTO> subsetDTOs = new ArrayList<>();
            
            for (Map<String, Object> subset : subsets) {
                SubsetDTO subsetDTO = new SubsetDTO();
                subsetDTO.setName((String) subset.get("name"));
                subsetDTO.setLabels((Map<String, String>) subset.get("labels"));
                subsetDTO.setTrafficPolicy((Map<String, Object>) subset.get("trafficPolicy"));
                
                subsetDTOs.add(subsetDTO);
            }
            
            dto.setSubsets(subsetDTOs);
        }
        
        return dto;
    }
}
```

#### 7.2.3 GitOps

GitOps是一种使用Git作为单一事实来源，自动化基础设施和应用程序部署的方法。

```java
// GitOps服务示例
@Service
public class GitOpsService {
    
    private final GitRepository gitRepository;
    private final KubernetesService kubernetesService;
    private final DeploymentHistoryRepository deploymentHistoryRepository;
    
    @Autowired
    public GitOpsService(
            GitRepository gitRepository,
            KubernetesService kubernetesService,
            DeploymentHistoryRepository deploymentHistoryRepository) {
        this.gitRepository = gitRepository;
        this.kubernetesService = kubernetesService;
        this.deploymentHistoryRepository = deploymentHistoryRepository;
    }
    
    public List<GitRepository> getAllRepositories() {
        return gitRepository.findAll();
    }
    
    public GitRepository getRepositoryById(Long repositoryId) {
        return gitRepository.findById(repositoryId)
                .orElseThrow(() -> new ResourceNotFoundException("Git仓库不存在: " + repositoryId));
    }
    
    public GitRepository addRepository(GitRepositoryDTO repositoryDTO) {
        // 验证Git仓库连接
        try {
            Git.cloneRepository()
                    .setURI(repositoryDTO.getUrl())
                    .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                            repositoryDTO.getUsername(), repositoryDTO.getPassword()))
                    .setDirectory(Files.createTempDirectory("git-test").toFile())
                    .setCloneAllBranches(false)
                    .setNoCheckout(true)
                    .call()
                    .close();
        } catch (Exception e) {
            throw new InvalidOperationException("无法连接到Git仓库: " + e.getMessage());
        }
        
        GitRepository repository = new GitRepository();
        repository.setName(repositoryDTO.getName());
        repository.setUrl(repositoryDTO.getUrl());
        repository.setUsername(repositoryDTO.getUsername());
        repository.setPassword(repositoryDTO.getPassword());
        repository.setBranch(repositoryDTO.getBranch());
        repository.setPath(repositoryDTO.getPath());
        repository.setCreatedAt(Instant.now());
        
        return gitRepository.save(repository);
    }
    
    public void deleteRepository(Long repositoryId) {
        GitRepository repository = gitRepository.findById(repositoryId)
                .orElseThrow(() -> new ResourceNotFoundException("Git仓库不存在: " + repositoryId));
        
        gitRepository.delete(repository);
    }
    
    public List<FileInfo> getRepositoryFiles(Long repositoryId) {
        GitRepository repository = getRepositoryById(repositoryId);
        
        File tempDir = null;
        try {
            tempDir = Files.createTempDirectory("git-repo").toFile();
            
            Git git = Git.cloneRepository()
                    .setURI(repository.getUrl())
                    .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                            repository.getUsername(), repository.getPassword()))
                    .setDirectory(tempDir)
                    .setBranch(repository.getBranch())
                    .call();
            
            git.close();
            
            File basePath = new File(tempDir, repository.getPath());
            if (!basePath.exists() || !basePath.isDirectory()) {
                throw new InvalidOperationException("仓库路径不存在或不是目录: " + repository.getPath());
            }
            
            return listFiles(basePath, basePath);
        } catch (Exception e) {
            throw new RuntimeException("获取仓库文件失败: " + e.getMessage(), e);
        } finally {
            if (tempDir != null) {
                try {
                    FileUtils.deleteDirectory(tempDir);
                } catch (IOException e) {
                    // 忽略
                }
            }
        }
    }
    
    public String getFileContent(Long repositoryId, String filePath) {
        GitRepository repository = getRepositoryById(repositoryId);
        
        File tempDir = null;
        try {
            tempDir = Files.createTempDirectory("git-repo").toFile();
            
            Git git = Git.cloneRepository()
                    .setURI(repository.getUrl())
                    .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                            repository.getUsername(), repository.getPassword()))
                    .setDirectory(tempDir)
                    .setBranch(repository.getBranch())
                    .call();
            
            git.close();
            
            File file = new File(tempDir, repository.getPath() + "/" + filePath);
            if (!file.exists() || !file.isFile()) {
                throw new ResourceNotFoundException("文件不存在: " + filePath);
            }
            
            return FileUtils.readFileToString(file, StandardCharsets.UTF_8);
        } catch (Exception e) {
            throw new RuntimeException("获取文件内容失败: " + e.getMessage(), e);
        } finally {
            if (tempDir != null) {
                try {
                    FileUtils.deleteDirectory(tempDir);
                } catch (IOException e) {
                    // 忽略
                }
            }
        }
    }
    
    public void updateFileContent(Long repositoryId, String filePath, String content, String commitMessage) {
        GitRepository repository = getRepositoryById(repositoryId);
        
        File tempDir = null;
        try {
            tempDir = Files.createTempDirectory("git-repo").toFile();
            
            Git git = Git.cloneRepository()
                    .setURI(repository.getUrl())
                    .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                            repository.getUsername(), repository.getPassword()))
                    .setDirectory(tempDir)
                    .setBranch(repository.getBranch())
                    .call();
            
            File file = new File(tempDir, repository.getPath() + "/" + filePath);
            if (!file.exists() || !file.isFile()) {
                throw new ResourceNotFoundException("文件不存在: " + filePath);
            }
            
            FileUtils.writeStringToFile(file, content, StandardCharsets.UTF_8);
            
            git.add().addFilepattern(repository.getPath() + "/" + filePath).call();
            git.commit().setMessage(commitMessage).call();
            git.push()
                    .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                            repository.getUsername(), repository.getPassword()))
                    .call();
            
            git.close();
        } catch (Exception e) {
            throw new RuntimeException("更新文件内容失败: " + e.getMessage(), e);
        } finally {
            if (tempDir != null) {
                try {
                    FileUtils.deleteDirectory(tempDir);
                } catch (IOException e) {
                    // 忽略
                }
            }
        }
    }
    
    public DeploymentResult deployToCluster(Long repositoryId, Long clusterId, String namespace) {
        GitRepository repository = getRepositoryById(repositoryId);
        
        File tempDir = null;
        try {
            tempDir = Files.createTempDirectory("git-repo").toFile();
            
            Git git = Git.cloneRepository()
                    .setURI(repository.getUrl())
                    .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                            repository.getUsername(), repository.getPassword()))
                    .setDirectory(tempDir)
                    .setBranch(repository.getBranch())
                    .call();
            
            git.close();
            
            File basePath = new File(tempDir, repository.getPath());
            if (!basePath.exists() || !basePath.isDirectory()) {
                throw new InvalidOperationException("仓库路径不存在或不是目录: " + repository.getPath());
            }
            
            KubernetesClient client = kubernetesService.createClient(clusterId);
            
            try {
                List<String> appliedResources = new ArrayList<>();
                List<String> failedResources = new ArrayList<>();
                
                // 递归处理所有YAML文件
                processDirectory(basePath, basePath, client, namespace, appliedResources, failedResources);
                
                // 记录部署历史
                DeploymentHistory history = new DeploymentHistory();
                history.setRepositoryId(repositoryId);
                history.setClusterId(clusterId);
                history.setNamespace(namespace);
                history.setBranch(repository.getBranch());
                history.setCommitId(getLatestCommitId(git));
                history.setDeployedAt(Instant.now());
                history.setStatus(failedResources.isEmpty() ? "SUCCESS" : "PARTIAL_FAILURE");
                history.setAppliedResources(String.join(",", appliedResources));
                history.setFailedResources(String.join(",", failedResources));
                
                deploymentHistoryRepository.save(history);
                
                return new DeploymentResult(
                        appliedResources.size(),
                        failedResources.size(),
                        appliedResources,
                        failedResources
                );
            } finally {
                client.close();
            }
        } catch (Exception e) {
            throw new RuntimeException("部署到集群失败: " + e.getMessage(), e);
        } finally {
            if (tempDir != null) {
                try {
                    FileUtils.deleteDirectory(tempDir);
                } catch (IOException e) {
                    // 忽略
                }
            }
        }
    }
    
    public List<DeploymentHistory> getDeploymentHistory(Long repositoryId) {
        return deploymentHistoryRepository.findByRepositoryIdOrderByDeployedAtDesc(repositoryId);
    }
    
    private List<FileInfo> listFiles(File baseDir, File dir) {
        List<FileInfo> files = new ArrayList<>();
        
        for (File file : dir.listFiles()) {
            String relativePath = baseDir.toPath().relativize(file.toPath()).toString();
            
            if (file.isDirectory()) {
                files.add(new FileInfo(relativePath, "directory", null));
                files.addAll(listFiles(baseDir, file));
            } else {
                String fileType = getFileType(file.getName());
                files.add(new FileInfo(relativePath, fileType, file.length()));
            }
        }
        
        return files;
    }
    
    private String getFileType(String fileName) {
        int dotIndex = fileName.lastIndexOf('.');
        if (dotIndex > 0 && dotIndex < fileName.length() - 1) {
            return fileName.substring(dotIndex + 1).toLowerCase();
        }
        return "unknown";
    }
    
    private void processDirectory(File baseDir, File dir, KubernetesClient client, String namespace,
                                 List<String> appliedResources, List<String> failedResources) {
        for (File file : dir.listFiles()) {
            if (file.isDirectory()) {
                processDirectory(baseDir, file, client, namespace, appliedResources, failedResources);
            } else if (file.getName().endsWith(".yaml") || file.getName().endsWith(".yml")) {
                try {
                    String relativePath = baseDir.toPath().relativize(file.toPath()).toString();
                    String content = FileUtils.readFileToString(file, StandardCharsets.UTF_8);
                    
                    // 应用YAML资源
                    client.load(new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8)))
                            .inNamespace(namespace)
                            .createOrReplace();
                    
                    appliedResources.add(relativePath);
                } catch (Exception e) {
                    failedResources.add(file.getName() + " (" + e.getMessage() + ")");
                }
            }
        }
    }
    
    private String getLatestCommitId(Git git) throws GitAPIException {
        Iterable<RevCommit> logs = git.log().setMaxCount(1).call();
        RevCommit latestCommit = logs.iterator().next();
        return latestCommit.getName();
    }
    
    @Scheduled(fixedRate = 300000) // 每5分钟执行一次
    public void syncRepositories() {
        List<GitRepository> repositories = gitRepository.findAll();
        
        for (GitRepository repository : repositories) {
            if (!repository.isAutoSync()) {
                continue;
            }
            
            File tempDir = null;
            try {
                tempDir = Files.createTempDirectory("git-repo").toFile();
                
                Git git = Git.cloneRepository()
                        .setURI(repository.getUrl())
                        .setCredentialsProvider(new UsernamePasswordCredentialsProvider(
                                repository.getUsername(), repository.getPassword()))
                        .setDirectory(tempDir)
                        .setBranch(repository.getBranch())
                        .call();
                
                String latestCommitId = getLatestCommitId(git);
                git.close();
                
                // 检查是否有新的提交
                if (!latestCommitId.equals(repository.getLastCommitId())) {
                    // 更新最后提交ID
                    repository.setLastCommitId(latestCommitId);
                    repository.setLastSyncAt(Instant.now());
                    gitRepository.save(repository);
                    
                    // 如果配置了自动部署，则部署到集群
                    if (repository.isAutoDeploy() && repository.getTargetClusterId() != null) {
                        deployToCluster(
                                repository.getId(),
                                repository.getTargetClusterId(),
                                repository.getTargetNamespace()
                        );
                    }
                }
            } catch (Exception e) {
                // 记录同步失败
                repository.setLastSyncError(e.getMessage());
                repository.setLastSyncAt(Instant.now());
                gitRepository.save(repository);
            } finally {
                if (tempDir != null) {
                    try {
                        FileUtils.deleteDirectory(tempDir);
                    } catch (IOException e) {
                        // 忽略
                    }
                }
            }
        }
    }
}
```

### 7.3 边缘计算

边缘计算是一种分布式计算范式，将计算和数据存储从中心化的云计算环境转移到更接近数据源的网络边缘，以减少延迟、节省带宽并提高响应速度。

#### 7.3.1 边缘节点管理

边缘节点管理是对分布在网络边缘的计算节点进行统一管理和控制的技术。

```java
// 边缘节点管理服务示例
@Service
public class EdgeNodeService {
    
    private final EdgeNodeRepository edgeNodeRepository;
    private final EdgeDeploymentRepository edgeDeploymentRepository;
    private final AlertService alertService;
    
    @Autowired
    public EdgeNodeService(
            EdgeNodeRepository edgeNodeRepository,
            EdgeDeploymentRepository edgeDeploymentRepository,
            AlertService alertService) {
        this.edgeNodeRepository = edgeNodeRepository;
        this.edgeDeploymentRepository = edgeDeploymentRepository;
        this.alertService = alertService;
    }
    
    public List<EdgeNode> getAllNodes() {
        return edgeNodeRepository.findAll();
    }
    
    public EdgeNode getNodeById(Long nodeId) {
        return edgeNodeRepository.findById(nodeId)
                .orElseThrow(() -> new ResourceNotFoundException("边缘节点不存在: " + nodeId));
    }
    
    public EdgeNode addNode(EdgeNodeDTO nodeDTO) {
        // 验证节点连接
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(nodeDTO.getHostname(), nodeDTO.getSshPort());
            sshClient.authPassword(nodeDTO.getSshUsername(), nodeDTO.getSshPassword());
            sshClient.disconnect();
        } catch (Exception e) {
            throw new InvalidOperationException("无法连接到边缘节点: " + e.getMessage());
        }
        
        EdgeNode node = new EdgeNode();
        node.setName(nodeDTO.getName());
        node.setHostname(nodeDTO.getHostname());
        node.setIpAddress(nodeDTO.getIpAddress());
        node.setLocation(nodeDTO.getLocation());
        node.setDescription(nodeDTO.getDescription());
        node.setSshPort(nodeDTO.getSshPort());
        node.setSshUsername(nodeDTO.getSshUsername());
        node.setSshPassword(nodeDTO.getSshPassword());
        node.setStatus("ONLINE");
        node.setCreatedAt(Instant.now());
        
        return edgeNodeRepository.save(node);
    }
    
    public void deleteNode(Long nodeId) {
        EdgeNode node = edgeNodeRepository.findById(nodeId)
                .orElseThrow(() -> new ResourceNotFoundException("边缘节点不存在: " + nodeId));
        
        // 检查是否有关联的部署
        List<EdgeDeployment> deployments = edgeDeploymentRepository.findByNodeId(nodeId);
        if (!deployments.isEmpty()) {
            throw new InvalidOperationException("无法删除节点，存在关联的部署");
        }
        
        edgeNodeRepository.delete(node);
    }
    
    public NodeStatus checkNodeStatus(Long nodeId) {
        EdgeNode node = getNodeById(nodeId);
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            // 获取系统信息
            Session session = sshClient.startSession();
            Command command = session.exec("cat /proc/cpuinfo | grep 'model name' | head -1 && " +
                    "cat /proc/meminfo | grep MemTotal && " +
                    "df -h / | tail -1 && " +
                    "uptime && " +
                    "docker info | grep 'Docker Root Dir' || echo 'Docker not installed'");
            
            String output = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8);
            command.join();
            session.close();
            
            // 解析输出
            String[] lines = output.split("\n");
            
            String cpuModel = "";
            String memoryTotal = "";
            String diskUs
让我继续完成自动化运维平台设计的内容：

### 7.3 边缘计算（续）

#### 7.3.1 边缘节点管理（续）

```java
            String[] lines = output.split("\n");
            
            String cpuModel = "";
            String memoryTotal = "";
            String diskUsage = "";
            String uptime = "";
            String dockerInfo = "";
            
            if (lines.length >= 1) {
                cpuModel = lines[0].replaceAll("model name\\s*:\\s*", "").trim();
            }
            
            if (lines.length >= 2) {
                memoryTotal = lines[1].replaceAll("MemTotal:\\s*", "").trim();
            }
            
            if (lines.length >= 3) {
                diskUsage = lines[2].trim();
            }
            
            if (lines.length >= 4) {
                uptime = lines[3].trim();
            }
            
            if (lines.length >= 5) {
                dockerInfo = lines[4].trim();
            }
            
            // 获取运行中的容器
            session = sshClient.startSession();
            command = session.exec("docker ps --format '{{.ID}}|{{.Image}}|{{.Status}}|{{.Names}}' || echo 'Docker not installed'");
            
            String containersOutput = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8);
            command.join();
            session.close();
            
            List<ContainerInfo> containers = new ArrayList<>();
            
            if (!containersOutput.contains("Docker not installed")) {
                String[] containerLines = containersOutput.split("\n");
                
                for (String containerLine : containerLines) {
                    if (containerLine.trim().isEmpty()) {
                        continue;
                    }
                    
                    String[] parts = containerLine.split("\\|");
                    if (parts.length >= 4) {
                        ContainerInfo container = new ContainerInfo();
                        container.setId(parts[0]);
                        container.setImage(parts[1]);
                        container.setStatus(parts[2]);
                        container.setName(parts[3]);
                        containers.add(container);
                    }
                }
            }
            
            sshClient.disconnect();
            
            // 更新节点状态
            node.setStatus("ONLINE");
            node.setLastCheckedAt(Instant.now());
            edgeNodeRepository.save(node);
            
            NodeStatus status = new NodeStatus();
            status.setCpuModel(cpuModel);
            status.setMemoryTotal(memoryTotal);
            status.setDiskUsage(diskUsage);
            status.setUptime(uptime);
            status.setDockerInfo(dockerInfo);
            status.setContainers(containers);
            
            return status;
        } catch (Exception e) {
            // 更新节点状态
            node.setStatus("OFFLINE");
            node.setLastCheckedAt(Instant.now());
            edgeNodeRepository.save(node);
            
            // 创建告警
            alertService.createAlert(
                    AlertLevel.WARNING,
                    "边缘节点离线",
                    String.format("边缘节点 %s (%s) 无法连接: %s", node.getName(), node.getHostname(), e.getMessage()),
                    "edge"
            );
            
            throw new RuntimeException("检查节点状态失败: " + e.getMessage(), e);
        }
    }
    
    public List<EdgeDeployment> getNodeDeployments(Long nodeId) {
        EdgeNode node = getNodeById(nodeId);
        return edgeDeploymentRepository.findByNodeId(nodeId);
    }
    
    public EdgeDeployment deployContainer(Long nodeId, ContainerDeployDTO deployDTO) {
        EdgeNode node = getNodeById(nodeId);
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            // 构建Docker运行命令
            StringBuilder command = new StringBuilder();
            command.append("docker run -d");
            
            // 添加名称
            command.append(" --name ").append(deployDTO.getName());
            
            // 添加重启策略
            command.append(" --restart ").append(deployDTO.getRestartPolicy());
            
            // 添加网络
            if (deployDTO.getNetwork() != null && !deployDTO.getNetwork().isEmpty()) {
                command.append(" --network ").append(deployDTO.getNetwork());
            }
            
            // 添加端口映射
            for (PortMapping portMapping : deployDTO.getPortMappings()) {
                command.append(" -p ").append(portMapping.getHostPort())
                        .append(":").append(portMapping.getContainerPort());
                
                if (portMapping.getProtocol() != null && !portMapping.getProtocol().isEmpty()) {
                    command.append("/").append(portMapping.getProtocol());
                }
            }
            
            // 添加卷挂载
            for (VolumeMount volumeMount : deployDTO.getVolumeMounts()) {
                command.append(" -v ").append(volumeMount.getHostPath())
                        .append(":").append(volumeMount.getContainerPath());
                
                if (volumeMount.getReadOnly()) {
                    command.append(":ro");
                }
            }
            
            // 添加环境变量
            for (EnvironmentVariable env : deployDTO.getEnvironmentVariables()) {
                command.append(" -e ").append(env.getName())
                        .append("=").append(env.getValue());
            }
            
            // 添加资源限制
            if (deployDTO.getCpuLimit() != null && !deployDTO.getCpuLimit().isEmpty()) {
                command.append(" --cpus ").append(deployDTO.getCpuLimit());
            }
            
            if (deployDTO.getMemoryLimit() != null && !deployDTO.getMemoryLimit().isEmpty()) {
                command.append(" --memory ").append(deployDTO.getMemoryLimit());
            }
            
            // 添加镜像和命令
            command.append(" ").append(deployDTO.getImage());
            
            if (deployDTO.getCommand() != null && !deployDTO.getCommand().isEmpty()) {
                command.append(" ").append(deployDTO.getCommand());
            }
            
            // 执行Docker命令
            Session session = sshClient.startSession();
            Command dockerCommand = session.exec(command.toString());
            
            String output = IOUtils.toString(dockerCommand.getInputStream(), StandardCharsets.UTF_8);
            String error = IOUtils.toString(dockerCommand.getErrorStream(), StandardCharsets.UTF_8);
            
            dockerCommand.join();
            session.close();
            
            if (dockerCommand.getExitStatus() != 0) {
                throw new RuntimeException("部署容器失败: " + error);
            }
            
            String containerId = output.trim();
            
            // 获取容器详细信息
            session = sshClient.startSession();
            dockerCommand = session.exec("docker inspect " + containerId);
            
            String inspectOutput = IOUtils.toString(dockerCommand.getInputStream(), StandardCharsets.UTF_8);
            dockerCommand.join();
            session.close();
            
            sshClient.disconnect();
            
            // 保存部署记录
            EdgeDeployment deployment = new EdgeDeployment();
            deployment.setNode(node);
            deployment.setName(deployDTO.getName());
            deployment.setImage(deployDTO.getImage());
            deployment.setContainerId(containerId);
            deployment.setStatus("RUNNING");
            deployment.setConfig(new ObjectMapper().writeValueAsString(deployDTO));
            deployment.setCreatedAt(Instant.now());
            
            return edgeDeploymentRepository.save(deployment);
        } catch (Exception e) {
            throw new RuntimeException("部署容器失败: " + e.getMessage(), e);
        }
    }
    
    public void stopContainer(Long nodeId, String containerId) {
        EdgeNode node = getNodeById(nodeId);
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            Session session = sshClient.startSession();
            Command command = session.exec("docker stop " + containerId);
            command.join();
            session.close();
            
            sshClient.disconnect();
            
            // 更新部署状态
            EdgeDeployment deployment = edgeDeploymentRepository.findByNodeIdAndContainerId(nodeId, containerId);
            if (deployment != null) {
                deployment.setStatus("STOPPED");
                deployment.setUpdatedAt(Instant.now());
                edgeDeploymentRepository.save(deployment);
            }
        } catch (Exception e) {
            throw new RuntimeException("停止容器失败: " + e.getMessage(), e);
        }
    }
    
    public void startContainer(Long nodeId, String containerId) {
        EdgeNode node = getNodeById(nodeId);
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            Session session = sshClient.startSession();
            Command command = session.exec("docker start " + containerId);
            command.join();
            session.close();
            
            sshClient.disconnect();
            
            // 更新部署状态
            EdgeDeployment deployment = edgeDeploymentRepository.findByNodeIdAndContainerId(nodeId, containerId);
            if (deployment != null) {
                deployment.setStatus("RUNNING");
                deployment.setUpdatedAt(Instant.now());
                edgeDeploymentRepository.save(deployment);
            }
        } catch (Exception e) {
            throw new RuntimeException("启动容器失败: " + e.getMessage(), e);
        }
    }
    
    public void removeContainer(Long nodeId, String containerId) {
        EdgeNode node = getNodeById(nodeId);
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            Session session = sshClient.startSession();
            Command command = session.exec("docker rm -f " + containerId);
            command.join();
            session.close();
            
            sshClient.disconnect();
            
            // 删除部署记录
            EdgeDeployment deployment = edgeDeploymentRepository.findByNodeIdAndContainerId(nodeId, containerId);
            if (deployment != null) {
                edgeDeploymentRepository.delete(deployment);
            }
        } catch (Exception e) {
            throw new RuntimeException("删除容器失败: " + e.getMessage(), e);
        }
    }
    
    public String getContainerLogs(Long nodeId, String containerId) {
        EdgeNode node = getNodeById(nodeId);
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            Session session = sshClient.startSession();
            Command command = session.exec("docker logs " + containerId);
            
            String output = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8);
            command.join();
            session.close();
            
            sshClient.disconnect();
            
            return output;
        } catch (Exception e) {
            throw new RuntimeException("获取容器日志失败: " + e.getMessage(), e);
        }
    }
    
    @Scheduled(fixedRate = 60000) // 每分钟执行一次
    public void monitorNodes() {
        List<EdgeNode> nodes = edgeNodeRepository.findAll();
        
        for (EdgeNode node : nodes) {
            try {
                SSHClient sshClient = new SSHClient();
                sshClient.addHostKeyVerifier(new PromiscuousVerifier());
                sshClient.connect(node.getHostname(), node.getSshPort(), 5000); // 5秒超时
                sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
                
                // 获取系统负载
                Session session = sshClient.startSession();
                Command command = session.exec("uptime && free -m && df -h / && docker ps -q | wc -l");
                
                String output = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8);
                command.join();
                session.close();
                
                sshClient.disconnect();
                
                // 解析输出
                String[] lines = output.split("\n");
                
                if (lines.length >= 1) {
                    String uptimeLine = lines[0];
                    // 提取负载信息
                    Pattern loadPattern = Pattern.compile("load average: ([0-9.]+), ([0-9.]+), ([0-9.]+)");
                    Matcher loadMatcher = loadPattern.matcher(uptimeLine);
                    
                    if (loadMatcher.find()) {
                        double load1 = Double.parseDouble(loadMatcher.group(1));
                        double load5 = Double.parseDouble(loadMatcher.group(2));
                        double load15 = Double.parseDouble(loadMatcher.group(3));
                        
                        // 检查负载是否过高
                        if (load1 > 2.0) { // 根据实际情况调整阈值
                            alertService.createAlert(
                                    AlertLevel.WARNING,
                                    "边缘节点负载过高",
                                    String.format("边缘节点 %s (%s) 1分钟负载为 %.2f",
                                            node.getName(), node.getHostname(), load1),
                                    "edge"
                            );
                        }
                    }
                }
                
                if (lines.length >= 3) {
                    String memoryLine = lines[2];
                    // 提取内存使用信息
                    Pattern memPattern = Pattern.compile("Mem:\\s+([0-9]+)\\s+([0-9]+)\\s+([0-9]+)");
                    Matcher memMatcher = memPattern.matcher(memoryLine);
                    
                    if (memMatcher.find()) {
                        int totalMem = Integer.parseInt(memMatcher.group(1));
                        int usedMem = Integer.parseInt(memMatcher.group(2));
                        
                        // 计算内存使用率
                        double memUsagePercent = (double) usedMem / totalMem * 100;
                        
                        // 检查内存使用率是否过高
                        if (memUsagePercent > 90) { // 根据实际情况调整阈值
                            alertService.createAlert(
                                    AlertLevel.WARNING,
                                    "边缘节点内存使用率过高",
                                    String.format("边缘节点 %s (%s) 内存使用率为 %.2f%%",
                                            node.getName(), node.getHostname(), memUsagePercent),
                                    "edge"
                            );
                        }
                    }
                }
                
                if (lines.length >= 4) {
                    String diskLine = lines[3];
                    // 提取磁盘使用信息
                    Pattern diskPattern = Pattern.compile("([0-9]+)%");
                    Matcher diskMatcher = diskPattern.matcher(diskLine);
                    
                    if (diskMatcher.find()) {
                        int diskUsagePercent = Integer.parseInt(diskMatcher.group(1));
                        
                        // 检查磁盘使用率是否过高
                        if (diskUsagePercent > 90) { // 根据实际情况调整阈值
                            alertService.createAlert(
                                    AlertLevel.WARNING,
                                    "边缘节点磁盘使用率过高",
                                    String.format("边缘节点 %s (%s) 磁盘使用率为 %d%%",
                                            node.getName(), node.getHostname(), diskUsagePercent),
                                    "edge"
                            );
                        }
                    }
                }
                
                // 更新节点状态
                node.setStatus("ONLINE");
                node.setLastCheckedAt(Instant.now());
                edgeNodeRepository.save(node);
            } catch (Exception e) {
                // 节点离线
                if (!"OFFLINE".equals(node.getStatus())) {
                    // 只有当状态从在线变为离线时才创建告警
                    alertService.createAlert(
                            AlertLevel.WARNING,
                            "边缘节点离线",
                            String.format("边缘节点 %s (%s) 无法连接: %s",
                                    node.getName(), node.getHostname(), e.getMessage()),
                            "edge"
                    );
                }
                
                node.setStatus("OFFLINE");
                node.setLastCheckedAt(Instant.now());
                edgeNodeRepository.save(node);
            }
        }
    }
}
```

#### 7.3.2 边缘数据同步

边缘数据同步是在边缘节点和中心云之间实现数据一致性的技术，支持离线操作和数据冲突解决。

```java
// 边缘数据同步服务示例
@Service
public class EdgeDataSyncService {
    
    private final EdgeNodeRepository edgeNodeRepository;
    private final DataSyncRepository dataSyncRepository;
    private final DataSyncLogRepository dataSyncLogRepository;
    
    @Autowired
    public EdgeDataSyncService(
            EdgeNodeRepository edgeNodeRepository,
            DataSyncRepository dataSyncRepository,
            DataSyncLogRepository dataSyncLogRepository) {
        this.edgeNodeRepository = edgeNodeRepository;
        this.dataSyncRepository = dataSyncRepository;
        this.dataSyncLogRepository = dataSyncLogRepository;
    }
    
    public List<DataSyncConfig> getAllSyncConfigs() {
        return dataSyncRepository.findAll();
    }
    
    public DataSyncConfig getSyncConfigById(Long configId) {
        return dataSyncRepository.findById(configId)
                .orElseThrow(() -> new ResourceNotFoundException("数据同步配置不存在: " + configId));
    }
    
    public DataSyncConfig createSyncConfig(DataSyncConfigDTO configDTO) {
        EdgeNode node = edgeNodeRepository.findById(configDTO.getNodeId())
                .orElseThrow(() -> new ResourceNotFoundException("边缘节点不存在: " + configDTO.getNodeId()));
        
        DataSyncConfig config = new DataSyncConfig();
        config.setNode(node);
        config.setName(configDTO.getName());
        config.setSourcePath(configDTO.getSourcePath());
        config.setTargetPath(configDTO.getTargetPath());
        config.setSyncDirection(configDTO.getSyncDirection());
        config.setSyncInterval(configDTO.getSyncInterval());
        config.setConflictStrategy(configDTO.getConflictStrategy());
        config.setEnabled(configDTO.isEnabled());
        config.setCreatedAt(Instant.now());
        
        return dataSyncRepository.save(config);
    }
    
    public void deleteSyncConfig(Long configId) {
        DataSyncConfig config = getSyncConfigById(configId);
        dataSyncRepository.delete(config);
    }
    
    public void enableSyncConfig(Long configId) {
        DataSyncConfig config = getSyncConfigById(configId);
        config.setEnabled(true);
        config.setUpdatedAt(Instant.now());
        dataSyncRepository.save(config);
    }
    
    public void disableSyncConfig(Long configId) {
        DataSyncConfig config = getSyncConfigById(configId);
        config.setEnabled(false);
        config.setUpdatedAt(Instant.now());
        dataSyncRepository.save(config);
    }
    
    public SyncResult syncNow(Long configId) {
        DataSyncConfig config = getSyncConfigById(configId);
        EdgeNode node = config.getNode();
        
        if (!"ONLINE".equals(node.getStatus())) {
            throw new InvalidOperationException("边缘节点离线，无法执行同步");
        }
        
        try {
            SSHClient sshClient = new SSHClient();
            sshClient.addHostKeyVerifier(new PromiscuousVerifier());
            sshClient.connect(node.getHostname(), node.getSshPort());
            sshClient.authPassword(node.getSshUsername(), node.getSshPassword());
            
            SyncResult result = new SyncResult();
            
            if ("TO_EDGE".equals(config.getSyncDirection()) || "BIDIRECTIONAL".equals(config.getSyncDirection())) {
                // 中心到边缘同步
                result.setCenterToEdge(syncCenterToEdge(sshClient, config));
            }
            
            if ("TO_CENTER".equals(config.getSyncDirection()) || "BIDIRECTIONAL".equals(config.getSyncDirection())) {
                // 边缘到中心同步
                result.setEdgeToCenter(syncEdgeToCenter(sshClient, config));
            }
            
            sshClient.disconnect();
            
            // 记录同步日志
            DataSyncLog log = new DataSyncLog();
            log.setConfig(config);
            log.setSyncTime(Instant.now());
            log.setStatus("SUCCESS");
            log.setFilesTransferred(result.getTotalFilesTransferred());
            log.setBytesTransferred(result.getTotalBytesTransferred());
            
            dataSyncLogRepository.save(log);
            
            // 更新最后同步时间
            config.setLastSyncAt(Instant.now());
            config.setLastSyncStatus("SUCCESS");
            dataSyncRepository.save(config);
            
            return result;
        } catch (Exception e) {
            // 记录同步失败日志
            DataSyncLog log = new DataSyncLog();
            log.setConfig(config);
            log.setSyncTime(Instant.now());
            log.setStatus("FAILED");
            log.setErrorMessage(e.getMessage());
            
            dataSyncLogRepository.save(log);
            
            // 更新最后同步时间和状态
            config.setLastSyncAt(Instant.now());
            config.setLastSyncStatus("FAILED");
            config.setLastSyncError(e.getMessage());
            dataSyncRepository.save(config);
            
            throw new RuntimeException("数据同步失败: " + e.getMessage(), e);
        }
    }
    
    private SyncStats syncCenterToEdge(SSHClient sshClient, DataSyncConfig config) throws IOException {
        // 确保目标目录存在
        Session session = sshClient.startSession();
        Command command = session.exec("mkdir -p " + config.getTargetPath());
        command.join();
        session.close();
        
        // 使用SCP将文件从中心传输到边缘
        File sourceDir = new File(config.getSourcePath());
        if (!sourceDir.exists() || !sourceDir.isDirectory()) {
            throw new InvalidOperationException("源目录不存在: " + config.getSourcePath());
        }
        
        SyncStats stats = new SyncStats();
        
        // 递归遍历源目录
        List<File> files = listFiles(sourceDir);
        
        for (File file : files) {
            String relativePath = sourceDir.toPath().relativize(file.toPath()).toString();
            String targetPath = config.getTargetPath() + "/" + relativePath;
            
            // 确保目标目录存在
            String targetDir = targetPath.substring(0, targetPath.lastIndexOf('/'));
            session = sshClient.startSession();
            command = session.exec("mkdir -p " + targetDir);
            command.join();
            session.close();
            
            // 检查目标文件是否存在
            session = sshClient.startSession();
            command = session.exec("ls -la " + targetPath + " 2>/dev/null || echo 'NOT_EXIST'");
            String output = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8);
            command.join();
            session.close();
            
            boolean targetExists = !output.contains("NOT_EXIST");
            
            if (targetExists && "SKIP".equals(config.getConflictStrategy())) {
                // 跳过已存在的文件
                continue;
            }
            
            if (targetExists && "COMPARE_TIMESTAMP".equals(config.getConflictStrategy())) {
                // 比较时间戳
                session = sshClient.startSession();
                command = session.exec("stat -c %Y " + targetPath);
                String timestampStr = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8).trim();
                command.join();
                session.close();
                
                long targetTimestamp = Long.parseLong(timestampStr);
                long sourceTimestamp = file.lastModified() / 1000; // 转换为秒
                
                if (sourceTimestamp <= targetTimestamp) {
                    // 源文件不比目标文件新，跳过
                    continue;
                }
            }
            
            // 传输文件
            try (SCPFileTransfer fileTransfer = sshClient.newSCPFileTransfer()) {
                fileTransfer.upload(file.getAbsolutePath(), targetPath);
                
                stats.setFilesTransferred(stats.getFilesTransferred() + 1);
                stats.setBytesTransferred(stats.getBytesTransferred() + file.length());
            }
        }
        
        return stats;
    }
    
    private SyncStats syncEdgeToCenter(SSHClient sshClient, DataSyncConfig config) throws IOException {
        // 确保目标目录存在
        File targetDir = new File(config.getTargetPath());
        if (!targetDir.exists()) {
            targetDir.mkdirs();
        }
        
        // 获取边缘节点上的文件列表
        Session session = sshClient.startSession();
        Command command = session.exec("find " + config.getSourcePath() + " -type f | sort");
        String output = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8);
        command.join();
        session.close();
        
        SyncStats stats = new SyncStats();
        
        String[] files = output.split("\n");
        for (String filePath : files) {
            if (filePath.trim().isEmpty()) {
                continue;
            }
            
            String relativePath = filePath.substring(config.getSourcePath().length());
            if (relativePath.startsWith("/")) {
                relativePath = relativePath.substring(1);
            }
            
            File targetFile = new File(targetDir, relativePath);
            
            // 确保目标目录存在
            File parentDir = targetFile.getParentFile();
            if (!parentDir.exists()) {
                parentDir.mkdirs();
            }
            
            // 检查目标文件是否存在
            boolean targetExists = targetFile.exists();
            
            if (targetExists && "SKIP".equals(config.getConflictStrategy())) {
                // 跳过已存在的文件
                continue;
            }
            
            if (targetExists && "COMPARE_TIMESTAMP".equals(config.getConflictStrategy())) {
                // 比较时间戳
                session = sshClient.startSession();
                command = session.exec("stat -c %Y " + filePath);
                String timestampStr = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8).trim();
                command.join();
                session.close();
                
                long sourceTimestamp = Long.parseLong(timestampStr);
                long targetTimestamp = targetFile.lastModified() / 1000; // 转换为秒
                
                if (sourceTimestamp <= targetTimestamp) {
                    // 源文件不比目标文件新，跳过
                    continue;
                }
            }
            
            // 获取文件大小
            session = sshClient.startSession();
            command = session.exec("stat -c %s " + filePath);
            String sizeStr = IOUtils.toString(command.getInputStream(), StandardCharsets.UTF_8).trim();
            command.join();
            session.close();
            
            long fileSize = Long.parseLong(sizeStr);
            
            // 传输文件
            try (SCPFileTransfer fileTransfer = sshClient.newSCPFileTransfer()) {
                fileTransfer.download(filePath, targetFile.getAbsolutePath());
                
                stats.setFilesTransferred(stats.getFilesTransferred() + 1);
                stats.setBytesTransferred(stats.getBytesTransferred() + fileSize);
            }
        }
        
        return stats;
    }
    
    private List<File> listFiles(File dir) {
        List<File> files = new ArrayList<>();
        
        for (File file : dir.listFiles()) {
            if (file.isDirectory()) {
                files.addAll(listFiles(file));
            } else {
                files.add(file);
            }
        }
        
        return files;
    }
    
    public List<DataSyncLog> getSyncLogs(Long configId) {
        DataSyncConfig config = getSyncConfigById(configId);
        return dataSyncLogRepository.findByConfigIdOrderByIdDesc(configId);
    }
    
    @Scheduled(fixedRate = 60000) // 每分钟执行一次
    public void scheduledSync() {
        List<DataSyncConfig> configs = dataSyncRepository.findByEnabled(true);
        
        for (DataSyncConfig config : configs) {
            // 检查是否到达同步间隔
            if (config.getLastSyncAt() != null) {
                long lastSyncTime = config.getLastSyncAt().getEpochSecond();
                long currentTime = Instant.now().getEpochSecond();
                long interval = config.getSyncInterval() * 60; // 转换为秒
                
                if (currentTime - lastSyncTime < interval) {
                    // 未到达同步间隔，跳过
                    continue;
                }
            }
            
            // 检查节点是否在线
            EdgeNode node = config.getNode();
            if (!"ONLINE".equals(node.get